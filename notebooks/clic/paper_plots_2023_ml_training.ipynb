{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "from uncertainties import ufloat\n",
    "import glob\n",
    "import pandas\n",
    "import json\n",
    "\n",
    "import mplhep\n",
    "mplhep.style.use(mplhep.style.CMS)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../mlpf/\")\n",
    "from plotting.plot_utils import pid_to_text, format_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir plots_mlpf_clic_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_array(histories, key):\n",
    "    combined_array = np.array(histories[0][key])\n",
    "    for ii in range(1, len(histories)):\n",
    "        combined_array = np.vstack([combined_array, np.array(histories[ii][key])])\n",
    "    return combined_array\n",
    "\n",
    "\n",
    "def get_full_history(hist_dir, verbose=False):\n",
    "    jsons = list(hist_dir.glob(\"history*.json\"))\n",
    "    if verbose:\n",
    "        print(f\"{hist_dir.parent} has {len(jsons)} hisotries\")\n",
    "    if len(jsons) == 0:\n",
    "        return {}, 0\n",
    "    jsons.sort(key=lambda x: int(x.name.split(\"_\")[1].split(\".\")[0]))  # sort according to epoch number\n",
    "\n",
    "    # initialize a dict with correct keys and empty lists as values\n",
    "    with open(jsons[0]) as h:\n",
    "        keys = json.load(h).keys()\n",
    "    full_history = {key: [] for key in keys}\n",
    "\n",
    "    # join epoch values to a full history\n",
    "    for path in jsons:\n",
    "        with open(path) as h:\n",
    "            epoch = json.load(h)\n",
    "            for key in epoch.keys():\n",
    "                full_history[key].append(epoch[key])\n",
    "\n",
    "    reg_loss = np.sum(\n",
    "        np.array([full_history[\"{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]),\n",
    "        axis=0,\n",
    "    )\n",
    "    val_reg_loss = np.sum(\n",
    "        np.array(\n",
    "            [full_history[\"val_{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    full_history.update({\"reg_loss\": reg_loss})\n",
    "    full_history.update({\"val_reg_loss\": val_reg_loss})\n",
    "\n",
    "    return full_history, len(jsons)\n",
    "\n",
    "\n",
    "def get_histories(train_dirs):\n",
    "    train_dirs = [Path(train_dir) for train_dir in train_dirs]\n",
    "    histories = []\n",
    "\n",
    "    for train_dir in train_dirs:\n",
    "        hist, N = get_full_history(hist_dir=train_dir / \"logs/history\")\n",
    "        if N > 0:\n",
    "            histories.append(hist)\n",
    "\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories_gnn_before = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning/clic_gnn_beforeHPO/*\")))\n",
    "histories_gnn_after = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_gnn_afterHPO/*\")))\n",
    "\n",
    "histories_tf_before = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_transformer_beforeHPO/*\")))\n",
    "histories_tf_after = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_transformer_afterHPO/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = {\n",
    "    \"gnn\": {\n",
    "        \"before\": {\n",
    "            \"val_loss\": get_combined_array(histories_gnn_before,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_gnn_before,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_gnn_before,\"val_met_iqr\"),\n",
    "        },\n",
    "        \"after\": {\n",
    "            \"val_loss\": get_combined_array(histories_gnn_after,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_gnn_after,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_gnn_after,\"val_met_iqr\"),\n",
    "        }\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"before\": {\n",
    "            \"val_loss\": get_combined_array(histories_tf_before,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_tf_before,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_tf_before,\"val_met_iqr\"),\n",
    "        },\n",
    "        \"after\": {\n",
    "            \"val_loss\": get_combined_array(histories_tf_after,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_tf_after,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_tf_after,\"val_met_iqr\"),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigdigits(mean, std):\n",
    "    return \"{:L}\".format(ufloat(mean, std))\n",
    "\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=12):\n",
    "    plt.figtext(x, y, r'tt+qq',  wrap=False, horizontalalignment='right', fontsize=fz)\n",
    "\n",
    "\n",
    "def cms_label(x0=0.12, y=0.90, s=None, fz=22):\n",
    "    # plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=fz)\n",
    "    # plt.figtext(x0+0.09, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=fz-3)\n",
    "    if s is not None:\n",
    "        t = plt.figtext(x=x0, y=y-0.15, s=s[:-1], fontsize=fz-6)\n",
    "\n",
    "\n",
    "def plot_variance_curve(array_list,\n",
    "                        labels,\n",
    "                        colors_styles,\n",
    "                        skip=0,\n",
    "                        ylim=None,\n",
    "                        save_path=None,\n",
    "                        x=0.45,\n",
    "                        y=0.53,\n",
    "                        loc=None,\n",
    "                        ylabel=None,\n",
    "                        custom_info=None,\n",
    "                        threshold=None\n",
    "                       ):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    final_means = []\n",
    "    final_stds = []\n",
    "    for ii, array in enumerate(array_list):\n",
    "        print(f\"{labels[ii]} is averaged over {array.shape[0]} trainings.\")\n",
    "        xx = np.array(range(array.shape[1])) + 1  # Epochs\n",
    "\n",
    "        xx = xx[skip:]\n",
    "        array = array[:, skip:]\n",
    "\n",
    "        std = np.std(array, axis=0)\n",
    "        mean = np.mean(array, axis=0)\n",
    "\n",
    "        col, sty = colors_styles[ii]\n",
    "        plt.plot(xx, mean, label=labels[ii], color=col, ls=sty)\n",
    "        plt.fill_between(xx, mean - std, mean + std, alpha=0.4, facecolor=col)\n",
    "\n",
    "        # Add individual loss curves\n",
    "        # plt.plot(np.tile(xx, reps=[10,1]).transpose(), array.transpose(), linewidth=0.2)\n",
    "\n",
    "        print(labels[ii] + \": {:s}\".format(sigdigits(mean[-1], std[-1])))\n",
    "        final_means.append(mean[-1])\n",
    "        final_stds.append(std[-1])\n",
    "\n",
    "    if threshold:\n",
    "        plt.axhline(threshold, ls=\"--\", color=\"black\", label=\"baseline PF\")    \n",
    "        \n",
    "#     plt.legend(bbox_to_anchor=(0.98, 0.78), loc=\"center right\")\n",
    "    legtitle = r\"$\\mathrm{t}\\overline{\\mathrm{t}}, \\gamma/\\mathrm{Z}^* \\rightarrow \\mathrm{hadrons}$\"\n",
    "    if loc is not None:\n",
    "        plt.legend(loc=loc, title=legtitle)\n",
    "    else:\n",
    "        plt.legend(title=legtitle)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    s=\"Mean and stddev of {:d} trainings\\n\".format(array.shape[0])\n",
    "    for ii, label in enumerate(labels):\n",
    "        if custom_info:\n",
    "            s += \"Final {}: ${:s}$\\n\".format(label, sigdigits(custom_info[ii]['mean'], custom_info[ii][\"std\"]))\n",
    "        else:\n",
    "            s += \"Final {}: ${:s}$\\n\".format(label, sigdigits(final_means[ii], final_stds[ii]))\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[1], bottom=ylim[0])\n",
    "\n",
    "    # plt.subplots_adjust(left=0.14)\n",
    "    \n",
    "    cms_label(x0=x, y=y, s=s, fz=24)\n",
    "    # run_label(x=0.9, y=0.89, fz=22)\n",
    "    if save_path:\n",
    "        plt.savefig(Path(save_path).with_suffix('.png'))\n",
    "        plt.savefig(Path(save_path).with_suffix('.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"val_loss\"], ret[\"gnn\"][\"after\"][\"val_loss\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"val_loss\"], ret[\"transformer\"][\"after\"][\"val_loss\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    ylim=[0, 20],\n",
    "                    save_path=\"plots_mlpf_clic_2023/loss.png\",\n",
    "                    x=0.20,\n",
    "                    y=0.85,\n",
    "                    ylabel=\"Total validation loss (a.u.)\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"jet_iqr\"], ret[\"gnn\"][\"after\"][\"jet_iqr\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"jet_iqr\"], ret[\"transformer\"][\"after\"][\"jet_iqr\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    save_path=\"plots_mlpf_clic_2023/jet_iqr.png\",\n",
    "                    x=0.20,\n",
    "                    y=0.85,\n",
    "                    ylim=(0, 0.3),\n",
    "                    ylabel=r\"jet response IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"met_iqr\"], ret[\"gnn\"][\"after\"][\"met_iqr\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"met_iqr\"], ret[\"transformer\"][\"after\"][\"met_iqr\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    save_path=\"plots_mlpf_clic_2023/met_iqr.png\",\n",
    "                    x=0.2,\n",
    "                    y=0.85,\n",
    "                    ylim=(0, 2),\n",
    "                    ylabel=r\"MET response IQR\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: scaling of inference timing with number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data_gpu_1 = open(\"../../models/clic2023_20230802/timing/mlpf-gnn/gpu_timing_1.txt\").read()\n",
    "timing_data_gpu_2 = open(\"../../models/clic2023_20230802/timing/mlpf-gnn/gpu_timing_2.txt\").read()\n",
    "timing_data_gpu_3 = open(\"../../models/clic2023_20230802/timing/mlpf-gnn/gpu_timing_2.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "nptcls = []\n",
    "ts = []\n",
    "\n",
    "for line in timing_data_gpu_1.strip().split(\"\\n\") + timing_data_gpu_2.strip().split(\"\\n\") + timing_data_gpu_3.strip().split(\"\\n\"):\n",
    "    batch, nptcl, t = line.split()\n",
    "    batches.append(int(batch))\n",
    "    nptcls.append(int(nptcl))\n",
    "    ts.append(float(t))\n",
    "    \n",
    "df = pandas.DataFrame()\n",
    "df[\"batch\"] = batches\n",
    "df[\"nptcl\"] = nptcls\n",
    "df[\"t\"] = ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['batch', 'nptcl'], as_index=False).agg({'t':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = df_agg[(df_agg[\"batch\"]==16) & (df_agg[\"nptcl\"]==256)][\"t\"][\"mean\"].values[0]/16\n",
    "\n",
    "plt.plot([256,20*256], [1,20], color=\"black\", ls=\"--\", lw=2, label=\"linear scaling\")\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"s\", \".\"]\n",
    "for batch, elem in df_agg.groupby(\"batch\"):\n",
    "    m = markers.pop(0)\n",
    "    plt.errorbar(\n",
    "        elem[\"nptcl\"],\n",
    "        elem[\"t\"][\"mean\"]/sf/batch,\n",
    "        elem[\"t\"][\"std\"]/sf/batch,\n",
    "        label=\"B={}\".format(batch),\n",
    "        marker=m)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.ylabel(\"Relative time per event\\nT(N,B) / T(256,16)\")\n",
    "plt.xlabel(\"Input elements per event, N\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd experiments-archive/timing/pandora\n",
    "#grep TIMER gun_np* | grep MyDDMarlinPandora\n",
    "\n",
    "timing_data_cpu = \"\"\"\n",
    "gun_np_100_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 13836.000 | 13836.583 | 11041.204   18211.2  2452.37 |      10 |   138.366 |\n",
    "gun_np_100_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 13863.000 | 13861.665 | 11451.365   17552.7  1725.47 |      10 |   138.617 |\n",
    "gun_np_100_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 12829.000 | 12828.634 | 8948.882   15546.3  2064.03 |      10 |   128.286 |\n",
    "gun_np_100_4.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 14907.000 | 14908.701 | 10741.859   18102.9  2524.65 |      10 |   149.087 |\n",
    "gun_np_100_5.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 13174.000 | 13173.000 | 9291.507   23493.5  4326.01 |      10 |   131.730 |\n",
    "gun_np_100_6.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 12383.000 | 12383.906 | 10438.694   14086.3  1404.91 |      10 |   123.839 |\n",
    "gun_np_100_7.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 12956.000 | 12955.911 | 10072.747   16893.5  2782.78 |      10 |   129.559 |\n",
    "gun_np_200_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 47395.000 | 47397.637 | 35578.270   55634.0  5259.41 |      10 |   473.976 |\n",
    "gun_np_200_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 49098.000 | 49099.168 | 43919.848   55204.7  3801.20 |      10 |   490.992 |\n",
    "gun_np_200_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 47285.000 | 47283.594 | 34430.031   52283.8  5227.59 |      10 |   472.836 |\n",
    "gun_np_200_4.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 45921.000 | 45919.754 | 31380.205   56530.5  8713.73 |      10 |   459.198 |\n",
    "gun_np_200_5.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 46047.000 | 46047.980 | 37939.055   57653.4  5632.91 |      10 |   460.480 |\n",
    "gun_np_200_6.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 46928.000 | 46930.746 | 36946.914   62604.0  8045.00 |      10 |   469.307 |\n",
    "gun_np_200_7.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 44988.000 | 44989.551 | 39393.648   48307.4  2795.09 |      10 |   449.896 |\n",
    "gun_np_25_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1278.000 |  1275.958 |  890.380    1750.9   258.73 |      10 |    12.760 |\n",
    "gun_np_25_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1611.000 |  1611.889 | 1061.231    2250.4   371.55 |      10 |    16.119 |\n",
    "gun_np_25_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1511.000 |  1513.813 |  821.452    2323.8   449.85 |      10 |    15.138 |\n",
    "gun_np_25_4.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1391.000 |  1393.518 |  884.898    2606.6   475.22 |      10 |    13.935 |\n",
    "gun_np_25_5.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1458.000 |  1457.076 |  843.642    2644.6   584.55 |      10 |    14.571 |\n",
    "gun_np_25_6.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1705.000 |  1706.138 |  906.869    3667.7   810.81 |      10 |    17.061 |\n",
    "gun_np_25_7.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1598.000 |  1598.356 | 1074.817    1955.7   286.26 |      10 |    15.984 |\n",
    "gun_np_50_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  3962.000 |  3962.514 | 2568.144    6292.2  1138.24 |      10 |    39.625 |\n",
    "gun_np_50_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  3771.000 |  3771.321 | 3111.184    4891.2   606.17 |      10 |    37.713 |\n",
    "gun_np_50_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  4266.000 |  4266.345 | 3128.854    5726.2   918.44 |      10 |    42.663 |\n",
    "gun_np_50_4.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  4008.000 |  4007.004 | 3067.614    6363.1   935.73 |      10 |    40.070 |\n",
    "gun_np_50_5.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  3833.000 |  3834.250 | 2535.937    4735.0   781.68 |      10 |    38.343 |\n",
    "gun_np_50_6.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  3658.000 |  3662.497 | 2667.986    5553.0  1050.26 |      10 |    36.625 |\n",
    "gun_np_50_7.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  3844.000 |  3845.911 | 2562.266    6607.6  1196.24 |      10 |    38.459 |\n",
    "\"\"\"\n",
    "\n",
    "timing_data = {}\n",
    "for line in timing_data_cpu.strip().split(\"\\n\"):\n",
    "    lspl = line.split()\n",
    "    nptcl = int(lspl[0].split(\":\")[0].split(\"_\")[2])\n",
    "    dt = float(lspl[4])\n",
    "    if not (nptcl in timing_data):\n",
    "        timing_data[nptcl] = []\n",
    "    timing_data[nptcl].append(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "xs = []\n",
    "for k in sorted(timing_data.keys()):\n",
    "    means.append(np.mean(timing_data[k]))\n",
    "    stds.append(np.std(timing_data[k]))\n",
    "    xs.append(k)\n",
    "xs = np.array(xs)\n",
    "means = np.array(means)\n",
    "stds = np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xs, means/means[0], stds/means[0], marker=\"o\", label=\"baseline PF\")\n",
    "plt.plot([25,200], [1,8], color=\"black\", label=\"linear scaling\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"relative time per event, $T(N)/T(25)$\")\n",
    "plt.xlabel(\"$\\pi^-$ particles per event, $N$\")\n",
    "#plt.xlim(0,100)\n",
    "#plt.ylim(0,10)\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_gpu = sf\n",
    "\n",
    "num_tracks_clusters_pi100 = np.array([[93 , 182],\n",
    "[95 , 200],\n",
    "[93 , 191],\n",
    "[96 , 127],\n",
    "[95 , 153],\n",
    "[98 , 166],\n",
    "[98 , 151],\n",
    "[104, 158],\n",
    "[97 , 156],\n",
    "[93 , 175]])\n",
    "\n",
    "\n",
    "throughput_cpu = (means[2]/1000/10)\n",
    "\n",
    "print(throughput_cpu, throughput_gpu)\n",
    "print(num_tracks_clusters_pi100.mean(axis=0))\n",
    "print(num_tracks_clusters_pi100.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: jet and MET IQR for the hit-based training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = sorted(list(glob.glob(\"../../models/clic2023_20230802/hits/clic-hits-ln_*/logs/history/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = []\n",
    "val_loss_vals = []\n",
    "\n",
    "for hist in hists:\n",
    "    loss_vals.append(json.load(open(hist))[\"loss\"])\n",
    "    val_loss_vals.append(json.load(open(hist))[\"val_loss\"])\n",
    "\n",
    "loss_vals = np.array(loss_vals)\n",
    "val_loss_vals = np.array(val_loss_vals)\n",
    "\n",
    "plt.plot(loss_vals, label=\"train loss\", color=\"black\", ls=\"--\", marker=\"s\")\n",
    "plt.plot(val_loss_vals, label=\"val loss\", color=\"black\", marker=\"o\")\n",
    "\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlim(0, 22)\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "#plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.png\")\n",
    "#plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_iqr_vals = []\n",
    "met_iqr_vals = []\n",
    "\n",
    "xvals = np.arange(1,11)\n",
    "for hist in hists:\n",
    "    jet_iqr_vals.append(json.load(open(hist))[\"val_jet_iqr\"])\n",
    "    met_iqr_vals.append(json.load(open(hist))[\"val_met_iqr\"])\n",
    "\n",
    "jet_iqr_vals = np.array(jet_iqr_vals)\n",
    "met_iqr_vals = np.array(met_iqr_vals)\n",
    "\n",
    "plt.plot(xvals, jet_iqr_vals, label=\"jet response IQR\", marker=\"o\")\n",
    "plt.plot(xvals, met_iqr_vals/5, label=\"MET response IQR / 5\", marker=\"o\")\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.ylim(0,0.2)\n",
    "plt.xlim(1, 10)\n",
    "plt.ylabel(\"Response IQR (a.u.)\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_med_vals = []\n",
    "met_med_vals = []\n",
    "\n",
    "for hist in hists:\n",
    "    jet_med_vals.append(json.load(open(hist))[\"val_jet_med\"])\n",
    "    met_med_vals.append(json.load(open(hist))[\"val_met_med\"])\n",
    "\n",
    "jet_med_vals = np.array(jet_med_vals)\n",
    "met_med_vals = np.array(met_med_vals)\n",
    "\n",
    "plt.plot(jet_med_vals, label=\"jet response median\", marker=\"o\")\n",
    "plt.plot(met_med_vals, label=\"MET response median\", marker=\"o\")\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.axhline(1.0, color=\"black\", ls=\"--\")\n",
    "plt.ylim(0.8,1.2)\n",
    "#plt.xlim(0, 12)\n",
    "\n",
    "plt.ylabel(\"Response median (a.u.)\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_med.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_med.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with a varying number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_scale_test(path=\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_h100/scale_testV3_*/result.json\"):\n",
    "    num_gpus = []\n",
    "    epoch_times = []\n",
    "    epoch_times_std = []\n",
    "    horovod_enabled = []\n",
    "    df = pandas.DataFrame()\n",
    "    for fn in glob.glob(path):\n",
    "        data = json.load(open(fn))\n",
    "        epoch_times.append(np.mean(data[\"wl-stats\"][\"epoch_times\"][1:]))\n",
    "        epoch_times_std.append(np.std(data[\"wl-stats\"][\"epoch_times\"][1:]))\n",
    "        num_gpus.append(data[\"wl-stats\"][\"GPU\"])\n",
    "        horovod_enabled.append(data[\"wl-stats\"].get(\"horovod_enabled\", False))\n",
    "\n",
    "    df[\"num_gpus\"] = num_gpus\n",
    "    df[\"epoch_times\"] = epoch_times\n",
    "    df[\"epoch_times_std\"] = epoch_times_std\n",
    "    df[\"horovod_enabled\"] = horovod_enabled\n",
    "    df = df.sort_values(\"num_gpus\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h100 = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_h100/*/result.json\")\n",
    "df_mi250x = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_mi250x/*/result.json\")\n",
    "df_hpu = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_gaudi/*/result.json\")\n",
    "df_hpu2 = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_gaudi2/*/result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,8],[1,8], color=\"black\", ls=\"--\", label=\"linear scaling\")\n",
    "plt.plot(\n",
    "    df_h100[\"num_gpus\"].values,\n",
    "    df_h100[\"epoch_times\"].values[0]/df_h100[\"epoch_times\"].values,\n",
    "    marker=\"o\", label=\"CoreSite (H100)\")\n",
    "plt.plot(\n",
    "    df_mi250x[\"num_gpus\"].values,\n",
    "    df_mi250x[\"epoch_times\"].values[0]/df_mi250x[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"LUMI (MI250X)\")\n",
    "plt.plot(\n",
    "    df_hpu[\"num_gpus\"].values,\n",
    "    df_hpu[\"epoch_times\"].values[0]/df_hpu[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi1)\")\n",
    "plt.plot(\n",
    "    df_hpu2[\"num_gpus\"].values,\n",
    "    df_hpu2[\"epoch_times\"].values[0]/df_hpu2[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi2)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Accelerator processors, N\")\n",
    "plt.ylabel(\"Speedup over single accelerator, T(1)/T(N)\")\n",
    "plt.savefig(\"./plots_mlpf_clic_2023/scale_test.pdf\")\n",
    "plt.savefig(\"./plots_mlpf_clic_2023/scale_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    df_h100[\"num_gpus\"].values,\n",
    "    df_h100[\"epoch_times\"].values,\n",
    "    marker=\"o\", label=\"CoreSite (H100)\")\n",
    "plt.plot(\n",
    "    df_mi250x[\"num_gpus\"].values,\n",
    "    df_mi250x[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"LUMI (MI250X)\")\n",
    "plt.plot(\n",
    "    df_hpu[\"num_gpus\"].values,\n",
    "    df_hpu[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi1)\")\n",
    "plt.plot(\n",
    "    df_hpu2[\"num_gpus\"].values,\n",
    "    df_hpu2[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi2)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Accelerator processors, N\")\n",
    "plt.ylabel(\"time per epoch, T(N) [s]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
