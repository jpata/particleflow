{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import json\n",
    "from uncertainties import ufloat\n",
    "import glob\n",
    "import pandas\n",
    "import json\n",
    "\n",
    "import mplhep\n",
    "mplhep.style.use(mplhep.style.CMS)\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../mlpf/\")\n",
    "from plotting.plot_utils import pid_to_text, format_dataset_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir plots_mlpf_clic_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_array(histories, key):\n",
    "    combined_array = np.array(histories[0][key])\n",
    "    for ii in range(1, len(histories)):\n",
    "        combined_array = np.vstack([combined_array, np.array(histories[ii][key])])\n",
    "    return combined_array\n",
    "\n",
    "\n",
    "def get_full_history(hist_dir, verbose=False):\n",
    "    jsons = list(hist_dir.glob(\"history*.json\"))\n",
    "    if verbose:\n",
    "        print(f\"{hist_dir.parent} has {len(jsons)} hisotries\")\n",
    "    if len(jsons) == 0:\n",
    "        return {}, 0\n",
    "    jsons.sort(key=lambda x: int(x.name.split(\"_\")[1].split(\".\")[0]))  # sort according to epoch number\n",
    "\n",
    "    # initialize a dict with correct keys and empty lists as values\n",
    "    with open(jsons[0]) as h:\n",
    "        keys = json.load(h).keys()\n",
    "    full_history = {key: [] for key in keys}\n",
    "\n",
    "    # join epoch values to a full history\n",
    "    for path in jsons:\n",
    "        with open(path) as h:\n",
    "            epoch = json.load(h)\n",
    "            for key in epoch.keys():\n",
    "                full_history[key].append(epoch[key])\n",
    "\n",
    "    reg_loss = np.sum(\n",
    "        np.array([full_history[\"{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]),\n",
    "        axis=0,\n",
    "    )\n",
    "    val_reg_loss = np.sum(\n",
    "        np.array(\n",
    "            [full_history[\"val_{}_loss\".format(l)] for l in [\"energy\", \"pt\", \"eta\", \"sin_phi\", \"cos_phi\", \"charge\"]]\n",
    "        ),\n",
    "        axis=0,\n",
    "    )\n",
    "    full_history.update({\"reg_loss\": reg_loss})\n",
    "    full_history.update({\"val_reg_loss\": val_reg_loss})\n",
    "\n",
    "    return full_history, len(jsons)\n",
    "\n",
    "\n",
    "def get_histories(train_dirs):\n",
    "    train_dirs = [Path(train_dir) for train_dir in train_dirs]\n",
    "    histories = []\n",
    "\n",
    "    for train_dir in train_dirs:\n",
    "        hist, N = get_full_history(hist_dir=train_dir / \"logs/history\")\n",
    "        if N > 0:\n",
    "            histories.append(hist)\n",
    "\n",
    "    return histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "histories_gnn_before = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning/clic_gnn_beforeHPO/*\")))\n",
    "histories_gnn_after = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_gnn_afterHPO/*\")))\n",
    "\n",
    "histories_tf_before = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_transformer_beforeHPO/*\")))\n",
    "histories_tf_after = get_histories(list(glob.glob(\"../../models/mlpf-clic-2023-results/hypertuning//clic_transformer_afterHPO/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret = {\n",
    "    \"gnn\": {\n",
    "        \"before\": {\n",
    "            \"val_loss\": get_combined_array(histories_gnn_before,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_gnn_before,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_gnn_before,\"val_met_iqr\"),\n",
    "        },\n",
    "        \"after\": {\n",
    "            \"val_loss\": get_combined_array(histories_gnn_after,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_gnn_after,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_gnn_after,\"val_met_iqr\"),\n",
    "        }\n",
    "    },\n",
    "    \"transformer\": {\n",
    "        \"before\": {\n",
    "            \"val_loss\": get_combined_array(histories_tf_before,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_tf_before,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_tf_before,\"val_met_iqr\"),\n",
    "        },\n",
    "        \"after\": {\n",
    "            \"val_loss\": get_combined_array(histories_tf_after,\"val_loss\"),\n",
    "            \"jet_iqr\": get_combined_array(histories_tf_after,\"val_jet_iqr\"),\n",
    "            \"met_iqr\": get_combined_array(histories_tf_after,\"val_met_iqr\"),\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigdigits(mean, std):\n",
    "    return \"{:L}\".format(ufloat(mean, std))\n",
    "\n",
    "\n",
    "def run_label(x=0.67, y=0.90, fz=12):\n",
    "    plt.figtext(x, y, r'tt+qq',  wrap=False, horizontalalignment='right', fontsize=fz)\n",
    "\n",
    "\n",
    "def cms_label(x0=0.12, y=0.90, s=None, fz=22):\n",
    "    # plt.figtext(x0, y,'CMS',fontweight='bold', wrap=True, horizontalalignment='left', fontsize=fz)\n",
    "    # plt.figtext(x0+0.09, y,'Simulation Preliminary', style='italic', wrap=True, horizontalalignment='left', fontsize=fz-3)\n",
    "    if s is not None:\n",
    "        t = plt.figtext(x=x0, y=y-0.15, s=s[:-1], fontsize=fz-6)\n",
    "\n",
    "\n",
    "def plot_variance_curve(array_list,\n",
    "                        labels,\n",
    "                        colors_styles,\n",
    "                        skip=0,\n",
    "                        ylim=None,\n",
    "                        save_path=None,\n",
    "                        x=0.45,\n",
    "                        y=0.53,\n",
    "                        loc=None,\n",
    "                        ylabel=None,\n",
    "                        custom_info=None,\n",
    "                        threshold=None\n",
    "                       ):\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    final_means = []\n",
    "    final_stds = []\n",
    "    for ii, array in enumerate(array_list):\n",
    "        print(f\"{labels[ii]} is averaged over {array.shape[0]} trainings.\")\n",
    "        xx = np.array(range(array.shape[1])) + 1  # Epochs\n",
    "\n",
    "        xx = xx[skip:]\n",
    "        array = array[:, skip:]\n",
    "\n",
    "        std = np.std(array, axis=0)\n",
    "        mean = np.mean(array, axis=0)\n",
    "\n",
    "        col, sty = colors_styles[ii]\n",
    "        plt.plot(xx, mean, label=labels[ii], color=col, ls=sty)\n",
    "        plt.fill_between(xx, mean - std, mean + std, alpha=0.4, facecolor=col)\n",
    "\n",
    "        # Add individual loss curves\n",
    "        # plt.plot(np.tile(xx, reps=[10,1]).transpose(), array.transpose(), linewidth=0.2)\n",
    "\n",
    "        print(labels[ii] + \": {:s}\".format(sigdigits(mean[-1], std[-1])))\n",
    "        final_means.append(mean[-1])\n",
    "        final_stds.append(std[-1])\n",
    "\n",
    "    if threshold:\n",
    "        plt.axhline(threshold, ls=\"--\", color=\"black\", label=\"baseline PF\")    \n",
    "        \n",
    "#     plt.legend(bbox_to_anchor=(0.98, 0.78), loc=\"center right\")\n",
    "    legtitle = r\"$\\mathrm{t}\\overline{\\mathrm{t}}, \\gamma/\\mathrm{Z}^* \\rightarrow \\mathrm{hadrons}$\"\n",
    "    if loc is not None:\n",
    "        plt.legend(loc=loc, title=legtitle)\n",
    "    else:\n",
    "        plt.legend(title=legtitle)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    if ylabel:\n",
    "        plt.ylabel(ylabel)\n",
    "\n",
    "    s=\"Mean and stddev of {:d} trainings\\n\".format(array.shape[0])\n",
    "    for ii, label in enumerate(labels):\n",
    "        if custom_info:\n",
    "            s += \"Final {}: ${:s}$\\n\".format(label, sigdigits(custom_info[ii]['mean'], custom_info[ii][\"std\"]))\n",
    "        else:\n",
    "            s += \"Final {}: ${:s}$\\n\".format(label, sigdigits(final_means[ii], final_stds[ii]))\n",
    "\n",
    "    if ylim:\n",
    "        plt.ylim(top=ylim[1], bottom=ylim[0])\n",
    "\n",
    "    # plt.subplots_adjust(left=0.14)\n",
    "    \n",
    "    cms_label(x0=x, y=y, s=s, fz=24)\n",
    "    # run_label(x=0.9, y=0.89, fz=22)\n",
    "    if save_path:\n",
    "        plt.savefig(Path(save_path).with_suffix('.png'))\n",
    "        plt.savefig(Path(save_path).with_suffix('.pdf'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 4: hypertuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"val_loss\"], ret[\"gnn\"][\"after\"][\"val_loss\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"val_loss\"], ret[\"transformer\"][\"after\"][\"val_loss\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    ylim=[0, 20],\n",
    "                    save_path=\"plots_mlpf_clic_2023/loss.png\",\n",
    "                    x=0.20,\n",
    "                    y=0.85,\n",
    "                    ylabel=\"Total validation loss (a.u.)\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"jet_iqr\"], ret[\"gnn\"][\"after\"][\"jet_iqr\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"jet_iqr\"], ret[\"transformer\"][\"after\"][\"jet_iqr\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    save_path=\"plots_mlpf_clic_2023/jet_iqr.png\",\n",
    "                    x=0.20,\n",
    "                    y=0.85,\n",
    "                    ylim=(0, 0.3),\n",
    "                    ylabel=r\"jet response IQR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_variance_curve([ret[\"gnn\"][\"before\"][\"met_iqr\"], ret[\"gnn\"][\"after\"][\"met_iqr\"],\n",
    "                     ret[\"transformer\"][\"before\"][\"met_iqr\"], ret[\"transformer\"][\"after\"][\"met_iqr\"]],\n",
    "                    [\"GNN\", \"GNN-HPO\",\"TF\", \"TF-HPO\"],\n",
    "                    [(\"red\", \"--\"), (\"red\", \"-\"), (\"blue\", \"--\"), (\"blue\", \"-\")],\n",
    "                    skip=1,\n",
    "                    save_path=\"plots_mlpf_clic_2023/met_iqr.png\",\n",
    "                    x=0.2,\n",
    "                    y=0.85,\n",
    "                    ylim=(0, 2),\n",
    "                    ylabel=r\"MET response IQR\"\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 5: scaling of inference timing with number of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timing_data_gpu_1 = open(\"../../experiments/mlpf-clic-2023-results/timing/mlpf-gnn/gpu_timing_1.txt\").read()\n",
    "timing_data_gpu_2 = open(\"../../experiments/mlpf-clic-2023-results/timing/mlpf-gnn/gpu_timing_2.txt\").read()\n",
    "timing_data_gpu_3 = open(\"../../experiments/mlpf-clic-2023-results/timing/mlpf-gnn/gpu_timing_2.txt\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = []\n",
    "nptcls = []\n",
    "ts = []\n",
    "gpu_mems = []\n",
    "\n",
    "for line in timing_data_gpu_1.strip().split(\"\\n\") + timing_data_gpu_2.strip().split(\"\\n\") + timing_data_gpu_3.strip().split(\"\\n\"):\n",
    "    batch, nptcl, t, gpu_mem = line.split()\n",
    "    gpu_mem = float(gpu_mem[1:-1])\n",
    "    batches.append(int(batch))\n",
    "    nptcls.append(int(nptcl))\n",
    "    ts.append(float(t))\n",
    "    gpu_mems.append(gpu_mem)\n",
    "    \n",
    "df = pandas.DataFrame()\n",
    "df[\"batch\"] = batches\n",
    "df[\"nptcl\"] = nptcls\n",
    "df[\"t\"] = ts\n",
    "df[\"gpu_mem\"] = gpu_mems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_agg = df.groupby(['batch', 'nptcl'], as_index=False).agg({'t':['mean','std'], 'gpu_mem':['mean','std']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = df_agg[(df_agg[\"batch\"]==16) & (df_agg[\"nptcl\"]==256)][\"t\"][\"mean\"].values[0]/16\n",
    "\n",
    "# plt.plot([256,50*256], [1,20], color=\"black\", ls=\"--\", lw=2, label=\"linear scaling\")\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"s\", \".\"]\n",
    "for batch, elem in df_agg.groupby(\"batch\"):\n",
    "    m = markers.pop(0)\n",
    "    plt.errorbar(\n",
    "        elem[\"nptcl\"],\n",
    "        elem[\"t\"][\"mean\"]/batch,\n",
    "        elem[\"t\"][\"std\"]/batch,\n",
    "        label=\"B={}\".format(batch),\n",
    "        marker=m)\n",
    "\n",
    "plt.ylim(0,0.1)\n",
    "plt.legend(loc=\"best\", ncol=2)\n",
    "plt.ylabel(\"Time per event [s]\")\n",
    "plt.xlabel(\"Input elements per event\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn.pdf\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf = df_agg[(df_agg[\"batch\"]==16) & (df_agg[\"nptcl\"]==256)][\"gpu_mem\"][\"mean\"].values[0]/16\n",
    "\n",
    "markers = [\"o\", \"^\", \"v\", \"s\", \".\"]\n",
    "for batch, elem in df_agg.groupby(\"batch\"):\n",
    "    m = markers.pop(0)\n",
    "    plt.errorbar(\n",
    "        elem[\"nptcl\"],\n",
    "        elem[\"gpu_mem\"][\"mean\"],\n",
    "        label=\"B={}\".format(batch),\n",
    "        marker=m)\n",
    "\n",
    "plt.ylim(0,8000)\n",
    "plt.ylabel(\"GPU max used memory [MB]\")\n",
    "plt.xlabel(\"Input elements per event\")\n",
    "plt.legend(loc=\"best\", ncols=2)\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn_mem.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/mlpf_gnn_mem.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cd experiments-archive/timing/pandora\n",
    "#grep TIMER gun_np* | grep MyDDMarlinPandora\n",
    "\n",
    "timing_data_cpu = \"\"\"\n",
    "gun_np_100_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 12257.000 | 12258.470 | 8266.205   15065.3  2243.62 |      10 |   122.585 |\n",
    "gun_np_100_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 12584.000 | 12586.436 | 9306.140   16603.8  2254.28 |      10 |   125.864 |\n",
    "gun_np_100_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 13469.000 | 13469.058 | 10559.396   19125.7  2767.47 |      10 |   134.691 |\n",
    "gun_np_200_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 49543.000 | 49544.113 | 42125.613   66414.5  7608.42 |      10 |   495.441 |\n",
    "gun_np_200_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 48916.000 | 48917.770 | 40950.480   55557.2  4728.46 |      10 |   489.178 |\n",
    "gun_np_200_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            | 48926.000 | 48925.219 | 42309.555   58747.8  4478.12 |      10 |   489.252 |\n",
    "gun_np_25_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1589.000 |  1589.525 |  984.285    2906.3   572.88 |      10 |    15.895 |\n",
    "gun_np_25_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1586.000 |  1582.584 | 1205.349    2140.1   308.66 |      10 |    15.826 |\n",
    "gun_np_25_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  1769.000 |  1771.345 | 1069.436    2687.1   663.88 |      10 |    17.713 |\n",
    "gun_np_50_1.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  4398.000 |  4400.301 | 2351.540    6855.1  1404.28 |      10 |    44.003 |\n",
    "gun_np_50_2.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  4192.000 |  4190.113 | 2748.873    5741.2  1020.65 |      10 |    41.901 |\n",
    "gun_np_50_3.txt:TIMER.TIMER          INFO  MyDDMarlinPandora            |  4172.000 |  4173.470 | 3003.761    5711.3   834.70 |      10 |    41.735 |\n",
    "\"\"\"\n",
    "\n",
    "timing_data = {}\n",
    "for line in timing_data_cpu.strip().split(\"\\n\"):\n",
    "    lspl = line.split()\n",
    "    nptcl = int(lspl[0].split(\":\")[0].split(\"_\")[2])\n",
    "    dt = float(lspl[4])\n",
    "    if not (nptcl in timing_data):\n",
    "        timing_data[nptcl] = []\n",
    "    timing_data[nptcl].append(dt)\n",
    "\n",
    "\n",
    "timing_data_mem_raw = \"\"\"\n",
    "gun_np_100_1.txt:       Maximum resident set size (kbytes): 4200616\n",
    "gun_np_100_2.txt:       Maximum resident set size (kbytes): 4300108\n",
    "gun_np_100_3.txt:       Maximum resident set size (kbytes): 4216444\n",
    "gun_np_200_1.txt:       Maximum resident set size (kbytes): 7683184\n",
    "gun_np_200_2.txt:       Maximum resident set size (kbytes): 7648704\n",
    "gun_np_200_3.txt:       Maximum resident set size (kbytes): 7599044\n",
    "gun_np_25_1.txt:        Maximum resident set size (kbytes): 1953052\n",
    "gun_np_25_2.txt:        Maximum resident set size (kbytes): 2089588\n",
    "gun_np_25_3.txt:        Maximum resident set size (kbytes): 2045860\n",
    "gun_np_50_1.txt:        Maximum resident set size (kbytes): 2637660\n",
    "gun_np_50_2.txt:        Maximum resident set size (kbytes): 2808484\n",
    "gun_np_50_3.txt:        Maximum resident set size (kbytes): 2699452\n",
    "\"\"\"\n",
    "\n",
    "timing_data_mem = {}\n",
    "for line in timing_data_mem_raw.strip().split(\"\\n\"):\n",
    "    lspl = line.split()\n",
    "    nptcl = int(lspl[0].split(\":\")[0].split(\"_\")[2])\n",
    "    rss = float(lspl[6])\n",
    "    print(rss)\n",
    "    if not (nptcl in timing_data_mem):\n",
    "        timing_data_mem[nptcl] = []\n",
    "    timing_data_mem[nptcl].append(rss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "means = []\n",
    "stds = []\n",
    "xs = []\n",
    "for k in sorted(timing_data.keys()):\n",
    "    means.append(np.mean(timing_data[k]))\n",
    "    stds.append(np.std(timing_data[k]))\n",
    "    xs.append(k)\n",
    "xs = np.array(xs)\n",
    "means = np.array(means)\n",
    "stds = np.array(stds)\n",
    "\n",
    "\n",
    "means_mem = []\n",
    "stds_mem = []\n",
    "xs_mem = []\n",
    "for k in sorted(timing_data_mem.keys()):\n",
    "    means_mem.append(np.mean(timing_data_mem[k]))\n",
    "    stds_mem.append(np.std(timing_data_mem[k]))\n",
    "    xs_mem.append(k)\n",
    "xs_mem = np.array(xs_mem)\n",
    "means_mem = np.array(means_mem)\n",
    "stds_mem = np.array(stds_mem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xs_mem, means_mem/1000, stds_mem/1000, marker=\"o\", label=\"baseline PF\")\n",
    "#plt.plot([25,200], [1,8], color=\"black\", label=\"linear scaling\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"process max. used memory [MB]\")\n",
    "plt.xlabel(\"$\\pi^-$ particles per event\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf_mem.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf_mem.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.errorbar(xs, means/1000/10, stds/1000/10, marker=\"o\", label=\"baseline PF\")\n",
    "#plt.plot([25,200], [1,8], color=\"black\", label=\"linear scaling\", ls=\"--\")\n",
    "plt.legend()\n",
    "plt.ylabel(\"Time per event [s]\")\n",
    "plt.xlabel(\"$\\pi^-$ particles per event\")\n",
    "#plt.xlim(0,100)\n",
    "#plt.ylim(0,10)\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/baseline_pf.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_gpu = sf\n",
    "\n",
    "num_tracks_clusters_pi100 = np.array([[93 , 182],\n",
    "[95 , 200],\n",
    "[93 , 191],\n",
    "[96 , 127],\n",
    "[95 , 153],\n",
    "[98 , 166],\n",
    "[98 , 151],\n",
    "[104, 158],\n",
    "[97 , 156],\n",
    "[93 , 175]])\n",
    "\n",
    "\n",
    "throughput_cpu = (means[2]/1000/10)\n",
    "\n",
    "print(throughput_cpu, throughput_gpu)\n",
    "print(num_tracks_clusters_pi100.mean(axis=0))\n",
    "print(num_tracks_clusters_pi100.std(axis=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 6: jet and MET IQR for the hit-based training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hists = sorted(list(glob.glob(\"../../models/clic2023_20230802/hits/clic-hits-ln_*/logs/history/*\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vals = []\n",
    "val_loss_vals = []\n",
    "\n",
    "for hist in hists:\n",
    "    loss_vals.append(json.load(open(hist))[\"loss\"])\n",
    "    val_loss_vals.append(json.load(open(hist))[\"val_loss\"])\n",
    "\n",
    "loss_vals = np.array(loss_vals)\n",
    "val_loss_vals = np.array(val_loss_vals)\n",
    "\n",
    "plt.plot(loss_vals, label=\"train loss\", color=\"black\", ls=\"--\", marker=\"s\")\n",
    "plt.plot(val_loss_vals, label=\"val loss\", color=\"black\", marker=\"o\")\n",
    "\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.ylim(0,0.4)\n",
    "plt.xlim(0, 22)\n",
    "plt.ylabel(\"Validation loss\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "#plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.png\")\n",
    "#plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_iqr_vals = []\n",
    "met_iqr_vals = []\n",
    "\n",
    "xvals = np.arange(1,11)\n",
    "for hist in hists:\n",
    "    jet_iqr_vals.append(json.load(open(hist))[\"val_jet_iqr\"])\n",
    "    met_iqr_vals.append(json.load(open(hist))[\"val_met_iqr\"])\n",
    "\n",
    "jet_iqr_vals = np.array(jet_iqr_vals)\n",
    "met_iqr_vals = np.array(met_iqr_vals)\n",
    "\n",
    "plt.plot(xvals, jet_iqr_vals, label=\"jet response IQR\", marker=\"o\")\n",
    "plt.plot(xvals, met_iqr_vals/5, label=\"MET response IQR / 5\", marker=\"o\")\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.ylim(0,0.2)\n",
    "plt.xlim(1, 10)\n",
    "plt.ylabel(\"Response IQR (a.u.)\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_iqr.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jet_med_vals = []\n",
    "met_med_vals = []\n",
    "\n",
    "for hist in hists:\n",
    "    jet_med_vals.append(json.load(open(hist))[\"val_jet_med\"])\n",
    "    met_med_vals.append(json.load(open(hist))[\"val_met_med\"])\n",
    "\n",
    "jet_med_vals = np.array(jet_med_vals)\n",
    "met_med_vals = np.array(met_med_vals)\n",
    "\n",
    "plt.plot(jet_med_vals, label=\"jet response median\", marker=\"o\")\n",
    "plt.plot(met_med_vals, label=\"MET response median\", marker=\"o\")\n",
    "plt.legend(title=format_dataset_name(\"clic_edm_ttbar_pf\"))\n",
    "plt.axhline(1.0, color=\"black\", ls=\"--\")\n",
    "plt.ylim(0.8,1.2)\n",
    "#plt.xlim(0, 12)\n",
    "\n",
    "plt.ylabel(\"Response median (a.u.)\")\n",
    "plt.xlabel(\"Training epoch\")\n",
    "#plt.title(\"Training on tracks and calorimeter hits\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_med.png\")\n",
    "plt.savefig(\"plots_mlpf_clic_2023/hitbased_res_med.pdf\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling with a varying number of GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_scale_test(path=\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_h100/scale_testV3_*/result.json\"):\n",
    "    num_gpus = []\n",
    "    epoch_times = []\n",
    "    epoch_times_std = []\n",
    "    horovod_enabled = []\n",
    "    df = pandas.DataFrame()\n",
    "    for fn in glob.glob(path):\n",
    "        data = json.load(open(fn))\n",
    "        epoch_times.append(np.mean(data[\"wl-stats\"][\"epoch_times\"][1:]))\n",
    "        epoch_times_std.append(np.std(data[\"wl-stats\"][\"epoch_times\"][1:]))\n",
    "        num_gpus.append(data[\"wl-stats\"][\"GPU\"])\n",
    "        horovod_enabled.append(data[\"wl-stats\"].get(\"horovod_enabled\", False))\n",
    "\n",
    "    df[\"num_gpus\"] = num_gpus\n",
    "    df[\"epoch_times\"] = epoch_times\n",
    "    df[\"epoch_times_std\"] = epoch_times_std\n",
    "    df[\"horovod_enabled\"] = horovod_enabled\n",
    "    df = df.sort_values(\"num_gpus\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_h100 = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_h100/*/result.json\")\n",
    "df_mi250x = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_mi250x/*/result.json\")\n",
    "df_hpu = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_gaudi/*/result.json\")\n",
    "df_hpu2 = import_scale_test(\"../../models/mlpf-clic-2023-results/gpu_scaling/scale_test_gnn_gaudi2/*/result.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([1,8],[1,8], color=\"black\", ls=\"--\", label=\"linear scaling\")\n",
    "plt.plot(\n",
    "    df_h100[\"num_gpus\"].values,\n",
    "    df_h100[\"epoch_times\"].values[0]/df_h100[\"epoch_times\"].values,\n",
    "    marker=\"o\", label=\"CoreSite (H100)\")\n",
    "plt.plot(\n",
    "    df_mi250x[\"num_gpus\"].values,\n",
    "    df_mi250x[\"epoch_times\"].values[0]/df_mi250x[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"LUMI (MI250X)\")\n",
    "plt.plot(\n",
    "    df_hpu[\"num_gpus\"].values,\n",
    "    df_hpu[\"epoch_times\"].values[0]/df_hpu[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi1)\")\n",
    "plt.plot(\n",
    "    df_hpu2[\"num_gpus\"].values,\n",
    "    df_hpu2[\"epoch_times\"].values[0]/df_hpu2[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi2)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Accelerator processors, N\")\n",
    "plt.ylabel(\"Speedup over single accelerator, T(1)/T(N)\")\n",
    "plt.savefig(\"./plots_mlpf_clic_2023/scale_test.pdf\")\n",
    "plt.savefig(\"./plots_mlpf_clic_2023/scale_test.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(\n",
    "    df_h100[\"num_gpus\"].values,\n",
    "    df_h100[\"epoch_times\"].values,\n",
    "    marker=\"o\", label=\"CoreSite (H100)\")\n",
    "plt.plot(\n",
    "    df_mi250x[\"num_gpus\"].values,\n",
    "    df_mi250x[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"LUMI (MI250X)\")\n",
    "plt.plot(\n",
    "    df_hpu[\"num_gpus\"].values,\n",
    "    df_hpu[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi1)\")\n",
    "plt.plot(\n",
    "    df_hpu2[\"num_gpus\"].values,\n",
    "    df_hpu2[\"epoch_times\"].values,\n",
    "    marker=\"s\", label=\"Voyager (Gaudi2)\")\n",
    "plt.legend(loc=\"best\")\n",
    "plt.xlabel(\"Accelerator processors, N\")\n",
    "plt.ylabel(\"time per epoch, T(N) [s]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -lrt plots_mlpf_clic_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
