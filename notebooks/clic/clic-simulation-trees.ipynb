{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dab6b24b-3613-4616-b44b-220cbee098ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot\n",
    "import vector\n",
    "import awkward as ak\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.sparse import coo_matrix\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import pyhepmc\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551a5a92-b508-4dd5-8156-10f1061df685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concatenate_root_files(file_paths, tree_name=\"events\", collections=None, max_files=50):\n",
    "    \"\"\"\n",
    "    Open multiple ROOT files and concatenate their arrays.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    file_paths : list or str\n",
    "        List of file paths or glob pattern string (e.g., \"path/to/files/*.root\")\n",
    "    tree_name : str\n",
    "        Name of the tree to read (default: \"events\")\n",
    "    collections : list\n",
    "        List of collections/branches to read. If None, reads all branches\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary containing the concatenated arrays and metadata\n",
    "    \"\"\"\n",
    "    # Handle glob patterns\n",
    "    if isinstance(file_paths, str):\n",
    "        file_paths = list(glob.glob(file_paths))[:max_files]\n",
    "    \n",
    "    all_data = []\n",
    "    metadata = None\n",
    "    \n",
    "    for file_path in tqdm.tqdm(file_paths):\n",
    "        # Open ROOT file\n",
    "        fi = uproot.open(file_path)\n",
    "        arrs = fi[tree_name]\n",
    "        \n",
    "        # Get collection IDs from first file\n",
    "        if metadata is None:\n",
    "            metadata = fi.get(\"podio_metadata\")\n",
    "            collectionIDs = {\n",
    "                k: v\n",
    "                for k, v in zip(\n",
    "                    metadata.arrays(\"events___idTable/m_names\")[\"events___idTable/m_names\"][0],\n",
    "                    metadata.arrays(\"events___idTable/m_collectionIDs\")[\"events___idTable/m_collectionIDs\"][0],\n",
    "                )\n",
    "            }\n",
    "        \n",
    "        # Read arrays\n",
    "        if collections is None:\n",
    "            data = arrs.arrays()\n",
    "        else:\n",
    "            data = arrs.arrays(collections)\n",
    "            \n",
    "        all_data.append(data)\n",
    "        \n",
    "    # Concatenate arrays\n",
    "    concatenated_data = ak.concatenate(all_data)\n",
    "    \n",
    "    return {\n",
    "        \"data\": concatenated_data,\n",
    "        \"collectionIDs\": collectionIDs\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fbeb47-e3b9-4c40-8e69-13b2832db1ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subarr(arrs, subarr_name):\n",
    "    subfields = [f for f in arrs.fields if subarr_name in f]\n",
    "    ret = ak.Array({sf: arrs[sf] for sf in subfields})\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8738c140-1588-40fc-bd6e-ae5f44d4ccd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = concatenate_root_files(\n",
    "    \"/media/joosep/data/cld/subfolder_9/reco_p8_ee_tt_ecm365_*.root\",\n",
    "    collections = None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b70b377-b6c9-4451-9f2d-4932dc8db92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in prop_data.fields:\n",
    "    if \"SiTracks_Refitted\" in f:\n",
    "        print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6820cba-9a32-4fc1-83b5-a4f23aded130",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_coll = \"SiTracks_Refitted\"\n",
    "mc_coll = \"MCParticles\"\n",
    "\n",
    "prop_data = data[\"data\"]\n",
    "\n",
    "# maps the recoparticle track/cluster index (in tracks_begin,end and clusters_begin,end)\n",
    "# to the index in the track/cluster collection\n",
    "idx_rp_to_cluster = prop_data[\"_PandoraPFOs_clusters.index\"]\n",
    "idx_rp_to_track = prop_data[\"_PandoraPFOs_tracks.index\"]\n",
    "\n",
    "hit_data = {\n",
    "    \"ECALBarrel\": get_subarr(prop_data, \"ECALBarrel\"),\n",
    "    \"ECALEndcap\": get_subarr(prop_data, \"ECALEndcap\"),\n",
    "    \"HCALBarrel\": get_subarr(prop_data, \"HCALBarrel\"),\n",
    "    \"HCALEndcap\": get_subarr(prop_data, \"HCALEndcap\"),\n",
    "    \"HCALOther\": get_subarr(prop_data, \"HCALOther\"),\n",
    "    \"MUON\": get_subarr(prop_data, \"MUON\"),\n",
    "}\n",
    "\n",
    "def track_pt(omega):\n",
    "    a = 3 * 10**-4\n",
    "    b = 4  # B-field in tesla, from clicRec_e4h_input\n",
    "\n",
    "    return a * np.abs(b / omega)\n",
    "\n",
    "def gen_to_features(prop_data, iev):\n",
    "    gen_arr = prop_data[iev]\n",
    "    gen_arr = {k.replace(mc_coll + \".\", \"\"): gen_arr[k] for k in gen_arr.fields}\n",
    "\n",
    "    MCParticles_p4 = vector.awk(\n",
    "        ak.zip({\"mass\": gen_arr[\"mass\"], \"x\": gen_arr[\"momentum.x\"], \"y\": gen_arr[\"momentum.y\"], \"z\": gen_arr[\"momentum.z\"]})\n",
    "    )\n",
    "    gen_arr[\"pt\"] = MCParticles_p4.pt\n",
    "    gen_arr[\"eta\"] = MCParticles_p4.eta\n",
    "    gen_arr[\"phi\"] = MCParticles_p4.phi\n",
    "    gen_arr[\"energy\"] = MCParticles_p4.energy\n",
    "    gen_arr[\"sin_phi\"] = np.sin(gen_arr[\"phi\"])\n",
    "    gen_arr[\"cos_phi\"] = np.cos(gen_arr[\"phi\"])\n",
    "\n",
    "    # placeholder flag\n",
    "    gen_arr[\"ispu\"] = np.zeros_like(gen_arr[\"phi\"])\n",
    "\n",
    "    return {\n",
    "        \"PDG\": gen_arr[\"PDG\"],\n",
    "        \"generatorStatus\": gen_arr[\"generatorStatus\"],\n",
    "        \"charge\": gen_arr[\"charge\"],\n",
    "        \"pt\": gen_arr[\"pt\"],\n",
    "        \"eta\": gen_arr[\"eta\"],\n",
    "        \"phi\": gen_arr[\"phi\"],\n",
    "        \"sin_phi\": gen_arr[\"sin_phi\"],\n",
    "        \"cos_phi\": gen_arr[\"cos_phi\"],\n",
    "        \"energy\": gen_arr[\"energy\"],\n",
    "        \"ispu\": gen_arr[\"ispu\"],\n",
    "        \"simulatorStatus\": gen_arr[\"simulatorStatus\"],\n",
    "        \"gp_to_track\": np.zeros(len(gen_arr[\"PDG\"]), dtype=np.float64),\n",
    "        \"gp_to_cluster\": np.zeros(len(gen_arr[\"PDG\"]), dtype=np.float64),\n",
    "        \"jet_idx\": np.zeros(len(gen_arr[\"PDG\"]), dtype=np.int64),\n",
    "        \"daughters_begin\": gen_arr[\"daughters_begin\"],\n",
    "        \"daughters_end\": gen_arr[\"daughters_end\"],\n",
    "        \"index\": prop_data[\"_MCParticles_daughters.index\"][iev]\n",
    "    }\n",
    "\n",
    "def get_calohit_matrix_and_genadj(hit_data, calohit_links, iev, collectionIDs):\n",
    "    feats = [\"type\", \"cellID\", \"energy\", \"energyError\", \"time\", \"position.x\", \"position.y\", \"position.z\"]\n",
    "\n",
    "    hit_idx_global = 0\n",
    "    hit_idx_global_to_local = {}\n",
    "    hit_feature_matrix = []\n",
    "    for col in sorted(hit_data.keys()):\n",
    "        icol = collectionIDs[col]\n",
    "        hit_features = hits_to_features(hit_data[col], iev, col, feats)\n",
    "        hit_feature_matrix.append(hit_features)\n",
    "        for ihit in range(len(hit_data[col][col + \".energy\"][iev])):\n",
    "            hit_idx_global_to_local[hit_idx_global] = (icol, ihit)\n",
    "            hit_idx_global += 1\n",
    "    hit_idx_local_to_global = {v: k for k, v in hit_idx_global_to_local.items()}\n",
    "    hit_feature_matrix = ak.Record(\n",
    "        {k: ak.concatenate([hit_feature_matrix[i][k] for i in range(len(hit_feature_matrix))]) for k in hit_feature_matrix[0].fields}\n",
    "    )\n",
    "\n",
    "    # add all edges from genparticle to calohit\n",
    "    calohit_to_gen_weight = prop_data[\"CalohitMCTruthLink.weight\"][iev]\n",
    "    calohit_to_gen_calo_colid = prop_data[\"_CalohitMCTruthLink_from.collectionID\"][iev]\n",
    "    calohit_to_gen_gen_colid = prop_data[\"_CalohitMCTruthLink_to.collectionID\"][iev]\n",
    "    calohit_to_gen_calo_idx = prop_data[\"_CalohitMCTruthLink_from.index\"][iev]\n",
    "    calohit_to_gen_gen_idx = prop_data[\"_CalohitMCTruthLink_to.index\"][iev]\n",
    "    genparticle_to_hit_matrix_coo0 = []\n",
    "    genparticle_to_hit_matrix_coo1 = []\n",
    "    genparticle_to_hit_matrix_w = []\n",
    "    for calo_colid, calo_idx, gen_colid, gen_idx, w in zip(\n",
    "        calohit_to_gen_calo_colid,\n",
    "        calohit_to_gen_calo_idx,\n",
    "        calohit_to_gen_gen_colid,\n",
    "        calohit_to_gen_gen_idx,\n",
    "        calohit_to_gen_weight,\n",
    "    ):\n",
    "        genparticle_to_hit_matrix_coo0.append(gen_idx)\n",
    "        genparticle_to_hit_matrix_coo1.append(hit_idx_local_to_global[(calo_colid, calo_idx)])\n",
    "        genparticle_to_hit_matrix_w.append(w)\n",
    "\n",
    "    return (\n",
    "        hit_feature_matrix,\n",
    "        (np.array(genparticle_to_hit_matrix_coo0), np.array(genparticle_to_hit_matrix_coo1), np.array(genparticle_to_hit_matrix_w)),\n",
    "        hit_idx_local_to_global,\n",
    "    )\n",
    "\n",
    "def hits_to_features(hit_data, iev, coll, feats):\n",
    "    feat_arr = {f: hit_data[coll + \".\" + f][iev] for f in feats}\n",
    "\n",
    "    # set the subdetector type\n",
    "    sdcoll = \"subdetector\"\n",
    "    feat_arr[sdcoll] = np.zeros(len(feat_arr[\"type\"]), dtype=np.int32)\n",
    "    if coll.startswith(\"ECAL\"):\n",
    "        feat_arr[sdcoll][:] = 0\n",
    "    elif coll.startswith(\"HCAL\"):\n",
    "        feat_arr[sdcoll][:] = 1\n",
    "    else:\n",
    "        feat_arr[sdcoll][:] = 2\n",
    "\n",
    "    # hit elemtype is always 2\n",
    "    feat_arr[\"elemtype\"] = 2 * np.ones(len(feat_arr[\"type\"]), dtype=np.int32)\n",
    "\n",
    "    # precompute some approximate et, eta, phi\n",
    "    pos_mag = np.sqrt(feat_arr[\"position.x\"] ** 2 + feat_arr[\"position.y\"] ** 2 + feat_arr[\"position.z\"] ** 2)\n",
    "    px = (feat_arr[\"position.x\"] / pos_mag) * feat_arr[\"energy\"]\n",
    "    py = (feat_arr[\"position.y\"] / pos_mag) * feat_arr[\"energy\"]\n",
    "    pz = (feat_arr[\"position.z\"] / pos_mag) * feat_arr[\"energy\"]\n",
    "    feat_arr[\"et\"] = np.sqrt(px**2 + py**2)\n",
    "    feat_arr[\"eta\"] = 0.5 * np.log((feat_arr[\"energy\"] + pz) / (feat_arr[\"energy\"] - pz))\n",
    "    feat_arr[\"sin_phi\"] = py / feat_arr[\"energy\"]\n",
    "    feat_arr[\"cos_phi\"] = px / feat_arr[\"energy\"]\n",
    "\n",
    "    return ak.Record(feat_arr)\n",
    "\n",
    "def hit_cluster_adj(prop_data, hit_idx_local_to_global, iev):\n",
    "    coll_arr = prop_data[\"_PandoraClusters_hits.collectionID\"][iev]\n",
    "    idx_arr = prop_data[\"_PandoraClusters_hits.index\"][iev]\n",
    "    hits_begin = prop_data[\"PandoraClusters.hits_begin\"][iev]\n",
    "    hits_end = prop_data[\"PandoraClusters.hits_end\"][iev]\n",
    "\n",
    "    # index in the array of all hits\n",
    "    hit_to_cluster_matrix_coo0 = []\n",
    "    # index in the cluster array\n",
    "    hit_to_cluster_matrix_coo1 = []\n",
    "\n",
    "    # weight\n",
    "    hit_to_cluster_matrix_w = []\n",
    "\n",
    "    # loop over all clusters\n",
    "    for icluster in range(len(hits_begin)):\n",
    "\n",
    "        # get the slice in the hit array corresponding to this cluster\n",
    "        hbeg = hits_begin[icluster]\n",
    "        hend = hits_end[icluster]\n",
    "        idx_range = idx_arr[hbeg:hend]\n",
    "        coll_range = coll_arr[hbeg:hend]\n",
    "\n",
    "        # add edges from hit to cluster\n",
    "        for icol, idx in zip(coll_range, idx_range):\n",
    "            hit_to_cluster_matrix_coo0.append(hit_idx_local_to_global[(icol, idx)])\n",
    "            hit_to_cluster_matrix_coo1.append(icluster)\n",
    "            hit_to_cluster_matrix_w.append(1.0)\n",
    "    return hit_to_cluster_matrix_coo0, hit_to_cluster_matrix_coo1, hit_to_cluster_matrix_w\n",
    "\n",
    "def track_to_features(prop_data, iev):\n",
    "\n",
    "    track_arr = get_subarr(prop_data, track_coll)[iev]\n",
    "    # the following are needed since they are no longer defined under SiTracks_Refitted\n",
    "    track_arr_dQdx = prop_data[\"SiTracks_Refitted_dQdx\"][iev]\n",
    "    track_arr_trackStates = prop_data[\"_SiTracks_Refitted_trackStates\"][iev]\n",
    "\n",
    "    feats_from_track = [\"type\", \"chi2\", \"ndf\"]\n",
    "    ret = {feat: track_arr[track_coll + \".\" + feat] for feat in feats_from_track}\n",
    "\n",
    "    ret[\"dEdx\"] = track_arr_dQdx[\"SiTracks_Refitted_dQdx.dQdx.value\"]\n",
    "    ret[\"dEdxError\"] = track_arr_dQdx[\"SiTracks_Refitted_dQdx.dQdx.error\"]\n",
    "\n",
    "    # build the radiusOfInnermostHit variable\n",
    "    num_tracks = len(ret[\"dEdx\"])\n",
    "    innermost_radius = []\n",
    "    for itrack in range(num_tracks):\n",
    "\n",
    "        # select the track states corresponding to itrack\n",
    "        # pick the state AtFirstHit\n",
    "        # https://github.com/key4hep/EDM4hep/blob/fe5a54046a91a7e648d0b588960db7841aebc670/edm4hep.yaml#L220\n",
    "        ibegin = track_arr[track_coll + \".\" + \"trackStates_begin\"][itrack]\n",
    "        iend = track_arr[track_coll + \".\" + \"trackStates_end\"][itrack]\n",
    "\n",
    "        refX = track_arr_trackStates[\"_SiTracks_Refitted_trackStates\" + \".\" + \"referencePoint.x\"][ibegin:iend]\n",
    "        refY = track_arr_trackStates[\"_SiTracks_Refitted_trackStates\" + \".\" + \"referencePoint.y\"][ibegin:iend]\n",
    "        location = track_arr_trackStates[\"_SiTracks_Refitted_trackStates\" + \".\" + \"location\"][ibegin:iend]\n",
    "\n",
    "        istate = np.argmax(location == 2)  # 2 refers to AtFirstHit\n",
    "\n",
    "        innermost_radius.append(math.sqrt(refX[istate] ** 2 + refY[istate] ** 2))\n",
    "\n",
    "    ret[\"radiusOfInnermostHit\"] = np.array(innermost_radius)\n",
    "    feats_from_track = [\"type\", \"chi2\", \"ndf\"]\n",
    "    ret = {feat: track_arr[track_coll + \".\" + feat] for feat in feats_from_track}\n",
    "    n_tr = len(ret[\"type\"])\n",
    "\n",
    "    # get the index of the first track state\n",
    "    trackstate_idx = prop_data[track_coll][track_coll + \".trackStates_begin\"][iev]\n",
    "    # get the properties of the track at the first track state (at the origin)\n",
    "    for k in [\"tanLambda\", \"D0\", \"phi\", \"omega\", \"Z0\", \"time\"]:\n",
    "        ret[k] = ak.to_numpy(prop_data[\"_SiTracks_Refitted_trackStates\"][\"_SiTracks_Refitted_trackStates.\" + k][iev][trackstate_idx])\n",
    "\n",
    "    ret[\"pt\"] = ak.to_numpy(track_pt(ret[\"omega\"]))\n",
    "    ret[\"px\"] = ak.to_numpy(np.cos(ret[\"phi\"])) * ret[\"pt\"]\n",
    "    ret[\"py\"] = ak.to_numpy(np.sin(ret[\"phi\"])) * ret[\"pt\"]\n",
    "    ret[\"pz\"] = ak.to_numpy(ret[\"tanLambda\"]) * ret[\"pt\"]\n",
    "    ret[\"p\"] = np.sqrt(ret[\"px\"] ** 2 + ret[\"py\"] ** 2 + ret[\"pz\"] ** 2)\n",
    "    cos_theta = np.divide(ret[\"pz\"], ret[\"p\"], where=ret[\"p\"] > 0)\n",
    "    theta = np.arccos(cos_theta)\n",
    "    tt = np.tan(theta / 2.0)\n",
    "    eta = ak.to_numpy(-np.log(tt, where=tt > 0))\n",
    "    eta[tt <= 0] = 0.0\n",
    "    ret[\"eta\"] = eta\n",
    "\n",
    "    ret[\"sin_phi\"] = np.sin(ret[\"phi\"])\n",
    "    ret[\"cos_phi\"] = np.cos(ret[\"phi\"])\n",
    "\n",
    "    # track is always type 1\n",
    "    ret[\"elemtype\"] = 1 * np.ones(n_tr, dtype=np.float32)\n",
    "\n",
    "    return ak.Record(ret)\n",
    "\n",
    "def genparticle_track_adj(sitrack_links, iev):\n",
    "    trk_to_gen_trkidx = prop_data[\"_SiTracksMCTruthLink_from.index\"][iev]\n",
    "    trk_to_gen_genidx = prop_data[\"_SiTracksMCTruthLink_to.index\"][iev]\n",
    "    trk_to_gen_w = prop_data[\"SiTracksMCTruthLink.weight\"][iev]\n",
    "\n",
    "    genparticle_to_track_matrix_coo0 = ak.to_numpy(trk_to_gen_genidx)\n",
    "    genparticle_to_track_matrix_coo1 = ak.to_numpy(trk_to_gen_trkidx)\n",
    "    genparticle_to_track_matrix_w = ak.to_numpy(trk_to_gen_w)\n",
    "\n",
    "    return genparticle_to_track_matrix_coo0, genparticle_to_track_matrix_coo1, genparticle_to_track_matrix_w\n",
    "\n",
    "def cluster_to_features(prop_data, hit_features, hit_to_cluster, iev):\n",
    "    cluster_arr = get_subarr(prop_data, \"PandoraClusters\")[iev]\n",
    "    feats = [\"type\", \"position.x\", \"position.y\", \"position.z\", \"iTheta\", \"phi\", \"energy\"]\n",
    "    ret = {feat: cluster_arr[\"PandoraClusters.\" + feat] for feat in feats}\n",
    "\n",
    "    hit_idx = np.array(hit_to_cluster[0])\n",
    "    cluster_idx = np.array(hit_to_cluster[1])\n",
    "    cl_energy_ecal = []\n",
    "    cl_energy_hcal = []\n",
    "    cl_energy_other = []\n",
    "    num_hits = []\n",
    "    cl_sigma_x = []\n",
    "    cl_sigma_y = []\n",
    "    cl_sigma_z = []\n",
    "\n",
    "    n_cl = len(ret[\"energy\"])\n",
    "    for cl in range(n_cl):\n",
    "        msk_cl = cluster_idx == cl\n",
    "        hits = hit_idx[msk_cl]\n",
    "\n",
    "        num_hits.append(len(hits))\n",
    "\n",
    "        subdets = hit_features[\"subdetector\"][hits]\n",
    "\n",
    "        hits_energy = hit_features[\"energy\"][hits]\n",
    "\n",
    "        hits_posx = hit_features[\"position.x\"][hits]\n",
    "        hits_posy = hit_features[\"position.y\"][hits]\n",
    "        hits_posz = hit_features[\"position.z\"][hits]\n",
    "\n",
    "        energy_ecal = np.sum(hits_energy[subdets == 0])\n",
    "        energy_hcal = np.sum(hits_energy[subdets == 1])\n",
    "        energy_other = np.sum(hits_energy[subdets == 2])\n",
    "\n",
    "        cl_energy_ecal.append(energy_ecal)\n",
    "        cl_energy_hcal.append(energy_hcal)\n",
    "        cl_energy_other.append(energy_other)\n",
    "\n",
    "        # weighted standard deviation of cluster hits\n",
    "        sigma_x = weighted_avg_and_std(hits_posx, hits_energy)[1]\n",
    "        sigma_y = weighted_avg_and_std(hits_posy, hits_energy)[1]\n",
    "        sigma_z = weighted_avg_and_std(hits_posz, hits_energy)[1]\n",
    "        cl_sigma_x.append(sigma_x)\n",
    "        cl_sigma_y.append(sigma_y)\n",
    "        cl_sigma_z.append(sigma_z)\n",
    "\n",
    "    ret[\"energy_ecal\"] = np.array(cl_energy_ecal)\n",
    "    ret[\"energy_hcal\"] = np.array(cl_energy_hcal)\n",
    "    ret[\"energy_other\"] = np.array(cl_energy_other)\n",
    "    ret[\"num_hits\"] = np.array(num_hits)\n",
    "    ret[\"sigma_x\"] = np.array(cl_sigma_x)\n",
    "    ret[\"sigma_y\"] = np.array(cl_sigma_y)\n",
    "    ret[\"sigma_z\"] = np.array(cl_sigma_z)\n",
    "\n",
    "    tt = ak.to_numpy(np.tan(ret[\"iTheta\"] / 2.0))\n",
    "    eta = ak.to_numpy(-np.log(tt, where=tt > 0))\n",
    "    eta[tt <= 0] = 0.0\n",
    "    ret[\"eta\"] = eta\n",
    "\n",
    "    costheta = np.cos(ret[\"iTheta\"])\n",
    "    ez = ret[\"energy\"] * costheta\n",
    "    ret[\"et\"] = np.sqrt(ret[\"energy\"] ** 2 - ez**2)\n",
    "\n",
    "    # cluster is always type 2\n",
    "    ret[\"elemtype\"] = 2 * np.ones(n_cl, dtype=np.float32)\n",
    "\n",
    "    ret[\"sin_phi\"] = np.sin(ret[\"phi\"])\n",
    "    ret[\"cos_phi\"] = np.cos(ret[\"phi\"])\n",
    "\n",
    "    return ak.Record(ret)\n",
    "\n",
    "def weighted_avg_and_std(values, weights):\n",
    "    \"\"\"\n",
    "    Return the weighted average and standard deviation.\n",
    "\n",
    "    They weights are in effect first normalized so that they\n",
    "    sum to 1 (and so they must not all be 0).\n",
    "\n",
    "    values, weights -- NumPy ndarrays with the same shape.\n",
    "    \"\"\"\n",
    "    average = np.average(values, weights=weights)\n",
    "    # Fast and numerically precise:\n",
    "    variance = np.average((values - average) ** 2, weights=weights)\n",
    "    return (average, math.sqrt(variance))\n",
    "\n",
    "def add_daughters_to_status1(gen_features, genparticle_to_hit, genparticle_to_trk):\n",
    "    mask_status1 = gen_features[\"generatorStatus\"] == 1\n",
    "    dau_beg = gen_features[\"daughters_begin\"]\n",
    "    dau_end = gen_features[\"daughters_end\"]\n",
    "    dau_ind = gen_features[\"index\"]\n",
    "    genparticle_to_hit_additional_gp = []\n",
    "    genparticle_to_hit_additional_hit = []\n",
    "    genparticle_to_hit_additional_w = []\n",
    "    genparticle_to_trk_additional_gp = []\n",
    "    genparticle_to_trk_additional_trk = []\n",
    "    genparticle_to_trk_additional_w = []\n",
    "    for idx_st1 in np.where(mask_status1)[0]:\n",
    "        pdg = abs(gen_features[\"PDG\"][idx_st1])\n",
    "        if pdg not in [12, 14, 16]:\n",
    "            db = dau_beg[idx_st1]\n",
    "            de = dau_end[idx_st1]\n",
    "            daus = dau_ind[db:de]\n",
    "            for dau in daus:\n",
    "                dau_hit_idx = genparticle_to_hit[1][genparticle_to_hit[0] == dau]\n",
    "                dau_hit_w = genparticle_to_hit[2][genparticle_to_hit[0] == dau]\n",
    "                for dh_idx, dh_w in zip(dau_hit_idx, dau_hit_w):\n",
    "                    genparticle_to_hit_additional_gp.append(idx_st1)\n",
    "                    genparticle_to_hit_additional_hit.append(dh_idx)\n",
    "                    genparticle_to_hit_additional_w.append(dh_w)\n",
    "\n",
    "                dau_trk_idx = genparticle_to_trk[1][genparticle_to_trk[0] == dau]\n",
    "                dau_trk_w = genparticle_to_trk[2][genparticle_to_trk[0] == dau]\n",
    "                for dt_idx, dt_w in zip(dau_trk_idx, dau_trk_w):\n",
    "                    genparticle_to_trk_additional_gp.append(idx_st1)\n",
    "                    genparticle_to_trk_additional_trk.append(dt_idx)\n",
    "                    genparticle_to_trk_additional_w.append(dt_w)\n",
    "\n",
    "    genparticle_to_hit = (\n",
    "        np.concatenate([genparticle_to_hit[0], genparticle_to_hit_additional_gp]),\n",
    "        np.concatenate([genparticle_to_hit[1], genparticle_to_hit_additional_hit]),\n",
    "        np.concatenate([genparticle_to_hit[2], genparticle_to_hit_additional_w]),\n",
    "    )\n",
    "    genparticle_to_trk = (\n",
    "        np.concatenate([genparticle_to_trk[0], genparticle_to_trk_additional_gp]),\n",
    "        np.concatenate([genparticle_to_trk[1], genparticle_to_trk_additional_trk]),\n",
    "        np.concatenate([genparticle_to_trk[2], genparticle_to_trk_additional_w]),\n",
    "    )\n",
    "    return genparticle_to_hit, genparticle_to_trk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a45ab5-2800-4742-bc79-c1e56192f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7139a70-4e97-48e5-b36a-0605805813c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ch_links_to = prop_data[\"_CalohitMCTruthLink_to.index\"]\n",
    "ch_w = prop_data[\"CalohitMCTruthLink.weight\"]\n",
    "\n",
    "tr_links_to = prop_data[\"_SiTracksMCTruthLink_to.index\"]\n",
    "tr_w = prop_data[\"SiTracksMCTruthLink.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89480371-ad2b-4519-ba32-ee6f90eb0a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hit_arrs = []\n",
    "for iev in range(len(ch_links_to)):\n",
    "    arr = 0*np.array(prop_data[\"MCParticles.mass\"][iev])\n",
    "    for ihit, w in zip(ch_links_to[iev], ch_w[iev]):\n",
    "        arr[ihit] += w\n",
    "    hit_arrs.append(arr)\n",
    "hit_arr_calo = ak.Array(hit_arrs)\n",
    "\n",
    "hit_arrs = []\n",
    "for iev in range(len(tr_links_to)):\n",
    "    arr = 0*np.array(prop_data[\"MCParticles.mass\"][iev])\n",
    "    for ihit, w in zip(tr_links_to[iev], tr_w[iev]):\n",
    "        arr[ihit] += w\n",
    "    hit_arrs.append(arr)\n",
    "hit_arr_trk = ak.Array(hit_arrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951c3e1b-f5c4-47cb-87c9-c1b375ef29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_arr = get_subarr(prop_data, \"MCParticles\")\n",
    "MCParticles_p4 = vector.awk(\n",
    "    ak.zip({\"mass\": gen_arr[\"MCParticles.mass\"], \"x\": gen_arr[\"MCParticles.momentum.x\"], \"y\": gen_arr[\"MCParticles.momentum.y\"], \"z\": gen_arr[\"MCParticles.momentum.z\"]})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5e231b-d9f5-422e-ba76-a375352f0847",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk_st1 = gen_arr[\"MCParticles.generatorStatus\"] == 1\n",
    "msk_st0 = gen_arr[\"MCParticles.generatorStatus\"] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a17566-e9f3-464e-a659-497ad000eafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(\n",
    "    ak.flatten((hit_arr_calo/MCParticles_p4.energy)[hit_arr_calo>0]),\n",
    "    bins=np.logspace(-3,3,200), histtype=\"step\", label=\"calorimeter\");\n",
    "plt.hist(\n",
    "    ak.flatten((hit_arr_trk/MCParticles_p4.energy)[hit_arr_trk>0]),\n",
    "    bins=np.logspace(-3,3,200), histtype=\"step\", label=\"tracker\");\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.xlabel(\"particle-hit $\\sum{w} / E$\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90706d4c-6c4f-477b-ae70-969ef821ee5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(5,5))\n",
    "plt.hist(\n",
    "    ak.flatten(MCParticles_p4.pt[msk_st1]), bins=np.logspace(-2, 2, 200),\n",
    "    histtype=\"step\", label=\"status 1 particles\"\n",
    ");\n",
    "\n",
    "plt.hist(\n",
    "    ak.flatten(MCParticles_p4.pt[(msk_st1) & (hit_arr>0.0)]), bins=np.logspace(-2, 2, 200),\n",
    "    histtype=\"step\", label=\"status 1 with hits\"\n",
    ");\n",
    "\n",
    "plt.hist(\n",
    "    ak.flatten(MCParticles_p4.pt[(msk_st0) & (hit_arr>0.0)]), bins=np.logspace(-2, 2, 200),\n",
    "    histtype=\"step\", label=\"status 0 with hits\"\n",
    ");\n",
    "\n",
    "plt.xscale(\"log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97944dd-a83e-4fc5-b4e8-e7f257507846",
   "metadata": {},
   "outputs": [],
   "source": [
    "calohit_links = get_subarr(prop_data, \"CalohitMCTruthLink\")\n",
    "calohit_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b95e9a-fc88-45db-b934-0a7eddbe3c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"collectionIDs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f4594a-a4c3-4890-92ed-5f8609fa8a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "iev = 0\n",
    "\n",
    "gen_features = gen_to_features(prop_data, iev)\n",
    "hit_features, genparticle_to_hit, hit_idx_local_to_global = get_calohit_matrix_and_genadj(hit_data, calohit_links, iev, data[\"collectionIDs\"])\n",
    "hit_to_cluster = hit_cluster_adj(prop_data, hit_idx_local_to_global, iev)\n",
    "cluster_features = cluster_to_features(prop_data, hit_features, hit_to_cluster, iev)\n",
    "track_features = track_to_features(prop_data, iev)\n",
    "genparticle_to_trk = genparticle_track_adj(sitrack_links, iev)\n",
    "\n",
    "mask_status1 = gen_features[\"generatorStatus\"] == 1\n",
    "genparticle_to_hit, genparticle_to_trk = add_daughters_to_status1(gen_features, genparticle_to_hit, genparticle_to_trk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b9aebb-428b-4764-a4b5-9a6ed2f15d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gp = ak.count(gen_features[\"PDG\"])\n",
    "n_track = ak.count(track_features[\"type\"])\n",
    "n_hit = ak.count(hit_features[\"type\"])\n",
    "n_cluster = ak.count(cluster_features[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8210f9b1-b7c2-43ba-8cab-59834f7acd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_gp, n_track, n_hit, n_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af1a91a-16d6-4572-9136-d796af31038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_to_track = coo_matrix((genparticle_to_trk[2], (genparticle_to_trk[0], genparticle_to_trk[1])), shape=(n_gp, n_track)).max(axis=1).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48446bd6-5cd4-4e55-9873-2b0b07375bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_to_calohit = coo_matrix((genparticle_to_hit[2], (genparticle_to_hit[0], genparticle_to_hit[1])), shape=(n_gp, n_hit))\n",
    "calohit_to_cluster = coo_matrix((hit_to_cluster[2], (hit_to_cluster[0], hit_to_cluster[1])), shape=(n_hit, n_cluster))\n",
    "gp_to_cluster = (gp_to_calohit * calohit_to_cluster).sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80adbcd3-c613-4843-b50f-3c4e0a03b91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp_to_cluster.shape, gp_to_track.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a6f59f-56f4-4034-b7b5-1257e0006dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 20% of the hits of a track must come from the genparticle\n",
    "gp_in_tracker = np.array(gp_to_track >= 0.2)[:, 0]\n",
    "\n",
    "# at least 5% of the energy of the genparticle should be matched to a calorimeter cluster\n",
    "gp_in_calo = (np.array(gp_to_cluster)[:, 0] / gen_features[\"energy\"]) > 0.05\n",
    "\n",
    "gp_interacted_with_detector = gp_in_tracker | gp_in_calo\n",
    "\n",
    "gen_features[\"gp_to_track\"] = np.asarray(gp_to_track)[:, 0]\n",
    "gen_features[\"gp_to_cluster\"] = np.asarray(gp_to_cluster)[:, 0]\n",
    "\n",
    "mask_visible = ak.to_numpy(mask_status1 & gp_interacted_with_detector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e981fd89-b9b6-44a5-a039-54400ded33a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_to_graph(gen_features):\n",
    "    g = nx.DiGraph()\n",
    "    for igp in range(len(gen_features[\"PDG\"])):\n",
    "        g.add_node(igp)\n",
    "\n",
    "    for igen, (dau_beg, dau_end) in enumerate(zip(gen_features[\"daughters_begin\"], gen_features[\"daughters_end\"])):\n",
    "        dau_ind = gen_features[\"index\"]\n",
    "        for idau in dau_ind[dau_beg:dau_end]:\n",
    "            if idau != igen:\n",
    "                g.add_edge(igen, idau)\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e028fae0-255d-4198-b24a-d3711967b5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gen_to_graph(gen_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7894cc4-49a5-47f9-934d-8b4410652ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_node(st):\n",
    "    if st == 0:\n",
    "        return \"red\"\n",
    "    elif st == 1:\n",
    "        return \"blue\"\n",
    "    elif st == 2:\n",
    "        return \"green\"\n",
    "    else:\n",
    "        return \"gray\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aed29d7-987b-4729-a225-331fc0e86161",
   "metadata": {},
   "outputs": [],
   "source": [
    "node_color = [color_node(st) for st in gen_features[\"generatorStatus\"]]\n",
    "node_size = [np.clip(10*e, 1, 100) for e in gen_features[\"energy\"]]\n",
    "# node_size = [5+ssg.nodes[n][\"energy\"] for n in ssg.nodes]\n",
    "alpha1 = [np.clip(x, 0.1, 1.0) for x in np.array(gp_to_cluster)[:, 0]]\n",
    "alpha2 = [np.clip(x, 0.1, 1.0) for x in np.array(gp_to_track)[:, 0]]\n",
    "alpha = [max(a1, a2) for a1, a2 in zip(alpha1, alpha2)]\n",
    "labels = {n: \"{}\".format(abs(pid))+(\"*\" if vis else \"\") for n, pid, vis in zip(g.nodes, gen_features[\"PDG\"], mask_visible)}\n",
    "pos = nx.nx_agraph.graphviz_layout(g, prog=\"dot\")\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "nx.draw_networkx_nodes(\n",
    "    g, pos,\n",
    "    node_color=node_color,\n",
    "    node_size=node_size,\n",
    "    alpha = alpha,\n",
    ");\n",
    "nx.draw_networkx_edges(\n",
    "    g, pos, arrowsize=1, width=0.5, alpha=0.2,\n",
    "    node_size=node_size,\n",
    ");\n",
    "nx.draw_networkx_labels(\n",
    "    g, pos,\n",
    "    labels=labels,\n",
    "    font_size=2\n",
    ");\n",
    "plt.savefig(\"graph.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd666bd-bec8-4b60-bd9b-ceb82cd90ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25744a31-59f6-42cc-81df-debe748b4c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_totals = {\"train\": 0, \"test\": 0}\n",
    "for ds in glob.glob(\"/media/joosep/data/tensorflow_datasets/clic_edm_*/*/2.5.0/dataset_info.json\"):\n",
    "    splits = json.load(open(ds))[\"splits\"]\n",
    "    for spl in splits:\n",
    "        x = sum([int(x) for x in spl[\"shardLengths\"]])\n",
    "        split_totals[spl[\"name\"]] += x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eaf8240-27da-4897-bc0c-48d4c9d81a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_totals[\"train\"],split_totals[\"test\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
