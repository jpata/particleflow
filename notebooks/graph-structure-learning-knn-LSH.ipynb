{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "renewable-words",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch_sparse\n",
    "import torch_scatter\n",
    "import torch_cluster\n",
    "import torch_geometric\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lovely-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphBuildingLSH(torch.nn.Module):\n",
    "    def __init__(self, feature_dim, bin_size, max_num_bins, k, **kwargs):\n",
    "        super(GraphBuildingLSH, self).__init__(**kwargs)\n",
    "\n",
    "        self.k = k\n",
    "        self.bin_size = bin_size\n",
    "        self.max_num_bins = max_num_bins\n",
    "        self.codebook = torch.randn((feature_dim, max_num_bins//2))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        pass\n",
    "\n",
    "    def forward(self, x):\n",
    "        shp = x.shape #(batches, nodes, features)\n",
    "        n_bins = shp[1] // self.bin_size\n",
    "        \n",
    "        assert(n_bins <= self.max_num_bins)\n",
    "        mul = torch.matmul(x, self.codebook[:, :n_bins//2])\n",
    "        cmul = torch.cat([mul, -mul], axis=-1)\n",
    "        \n",
    "        bin_idx = torch.argmax(cmul, axis=-1)\n",
    "        bins_split = torch.reshape(torch.argsort(bin_idx), (shp[0], n_bins, shp[1]//n_bins))\n",
    "        \n",
    "        points_binned = torch.stack([\n",
    "            x[ibatch][bins_split[ibatch]]\n",
    "            for ibatch in range(x.shape[0])]\n",
    "        ) #(batches, bins, nodes, features)\n",
    "\n",
    "        #multiply binned feature dimension\n",
    "        dm_binned = torch.einsum(\"...ij,...kj->...ik\", points_binned, points_binned) \n",
    "        dm = torch.sigmoid(dm_binned) #(batches, bins, nodes, nodes)\n",
    "        \n",
    "        #(batches, bins, nodes, neighbors)\n",
    "        topk = torch.topk(dm, self.k, axis=-1)\n",
    "        \n",
    "        sps = []\n",
    "        for ibatch in range(dm.shape[0]):\n",
    "            src = []\n",
    "            dst = []\n",
    "            val = []\n",
    "            for ibin in range(dm.shape[1]):\n",
    "                inds_src = torch.arange(0, dm.shape[2])\n",
    "                inds_dst = topk.indices[ibatch, ibin]\n",
    "                global_indices_src = bins_split[ibatch, ibin][inds_src]\n",
    "                global_indices_dst = bins_split[ibatch, ibin][inds_dst]\n",
    "                vals = topk.values[ibatch, ibin]\n",
    "\n",
    "                for ineigh in range(inds_dst.shape[-1]):\n",
    "                    src.append(global_indices_src)\n",
    "                    dst.append(global_indices_dst[:, ineigh])\n",
    "                    val.append(vals[:, ineigh])\n",
    "\n",
    "            src = torch.cat(src)\n",
    "            dst = torch.cat(dst)\n",
    "            val = torch.cat(val)\n",
    "            \n",
    "            sp = torch.sparse_coo_tensor(\n",
    "                torch.stack([src, dst]), val,\n",
    "                requires_grad=True, size=(shp[1], shp[1])\n",
    "            )\n",
    "            sps.append(sp)\n",
    "            \n",
    "        #Sparse (batches, nodes, nodes)\n",
    "        sp = torch.stack(sps).coalesce()\n",
    "\n",
    "        return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fatal-appeal",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take a 3d sparse matrix, and output a 2d sparse matrix,\n",
    "#where the batch dimension has been stacked in a block-diagonal way\n",
    "def stacked_sparse(dm):\n",
    "    #dm.shape: (num_batch, nodes, nodes)\n",
    "    \n",
    "    vals = []\n",
    "    inds = []\n",
    "    for ibatch in range(dm.shape[0]):\n",
    "        ind = dm[ibatch].coalesce().indices()\n",
    "\n",
    "        ind += ibatch*dm.shape[1]\n",
    "        inds.append(ind)\n",
    "    \n",
    "   \n",
    "    edge_index = torch.cat(inds, axis=-1)  #(2, num_batch*nodes)\n",
    "    edge_values = dm.values() #(num_batch*nodes)\n",
    "    return edge_index, edge_values\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self, num_node_features):\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        feature_dim = 16\n",
    "        self.lin1 = torch.nn.Linear(num_node_features, feature_dim)\n",
    "        self.dm = GraphBuildingLSH(\n",
    "            feature_dim=feature_dim,\n",
    "            bin_size=100,\n",
    "            max_num_bins=200,\n",
    "            k=16\n",
    "        )\n",
    "        self.gcn = torch_geometric.nn.GCNConv(num_node_features, 32)\n",
    "        self.lin2 = torch.nn.Linear(32, 1)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        n_batches = x.shape[0]\n",
    "        n_points = x.shape[1]\n",
    "        \n",
    "        i1 = self.lin1(x) #(n_batches, nodes, feature_dim)\n",
    "        dm = self.dm(i1) #(n_batches, nodes, nodes)\n",
    "        \n",
    "        edge_index, edge_vals = stacked_sparse(dm)\n",
    "        \n",
    "        xflat = torch.reshape(x, (n_batches*n_points, x.shape[-1]))\n",
    "        i2 = self.gcn(xflat, edge_index, edge_vals) #(n_batches, nodes, 32)\n",
    "        i2 = torch.reshape(i2, (n_batches, n_points, i2.shape[-1]))\n",
    "\n",
    "        i3 = self.lin2(i2) #(n_batches, nodes, 1)\n",
    "        \n",
    "        return i3, dm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-checklist",
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate an event that contains particles with a uniform energy and spatial distribution\n",
    "#each particle generates deposits with a random smearing around itself until the energy is expended\n",
    "def generate_event(\n",
    "    mean_num_particles_per_event=1000,\n",
    "    max_particle_energy=10.0,\n",
    "    deposit_fraction=0.1,\n",
    "    lowest_energy_threshold=0.5,\n",
    "    deposit_pos_spread=0.02):\n",
    "    \n",
    "    particles = []\n",
    "    all_deposits = []\n",
    "    for ipart in range(np.random.poisson(mean_num_particles_per_event)):\n",
    "        energy = np.random.uniform(0, max_particle_energy)\n",
    "        pos_x = np.random.uniform(-1.0, 1.0)\n",
    "        pos_y = np.random.uniform(-1.0, 1.0)\n",
    "        orig_energy = energy\n",
    "        particles.append([orig_energy, pos_x, pos_y])\n",
    "        deposits = []\n",
    "        while energy > lowest_energy_threshold:\n",
    "            deposit_energy = np.random.normal(energy * deposit_fraction)\n",
    "            if deposit_energy > lowest_energy_threshold:\n",
    "                energy -= deposit_energy\n",
    "                deposit_x = np.random.uniform(pos_x-deposit_pos_spread, pos_x+deposit_pos_spread)\n",
    "                deposit_y = np.random.uniform(pos_y-deposit_pos_spread, pos_y+deposit_pos_spread)\n",
    "                deposits.append([deposit_energy, deposit_x, deposit_y, -1, ipart])\n",
    "        if len(deposits) > 0:\n",
    "            top_deposit_index = np.argsort(np.array([d[0] for d in deposits]))[-1]\n",
    "            deposits[top_deposit_index][3] = ipart\n",
    "            all_deposits.append(deposits)\n",
    "\n",
    "\n",
    "    particles_array = np.stack(particles)\n",
    "    deposits_array = np.concatenate(all_deposits)\n",
    "    particles_array_resized = np.zeros((deposits_array.shape[0], 3))\n",
    "\n",
    "    for ideposit in range(deposits_array.shape[0]):\n",
    "        particle_index = int(deposits_array[ideposit, 3])\n",
    "        if particle_index >= 0:\n",
    "            particles_array_resized[ideposit] = particles_array[particle_index]\n",
    "\n",
    "    deposits_array = deposits_array[:, :3]\n",
    "\n",
    "    return deposits_array, particles_array_resized\n",
    "\n",
    "#pad all events to the same size\n",
    "def generate_events(padded_size=5000, num_events=10):\n",
    "    evs = [generate_event() for i in range(num_events)]\n",
    "\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    for X, y in evs:\n",
    "        X = X[:padded_size]\n",
    "        y = y[:padded_size]\n",
    "        X = np.pad(X, ((0, padded_size - X.shape[0]), (0,0)))\n",
    "        y = np.pad(y, ((0, padded_size - y.shape[0]), (0,0)))\n",
    "        Xs.append(X)\n",
    "        ys.append(y)\n",
    "    X = np.stack(Xs)\n",
    "    y = np.stack(ys)\n",
    "\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reserved-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = generate_events(num_events=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ignored-sierra",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape #(num_events, num_signals_per_event, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(energy, pos_x, pos_y)\n",
    "X[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-southwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(energy, pos_x, pos_y)\n",
    "y[0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deadly-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "iev = 5\n",
    "ymsk = y[iev, :, 0]!=0\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X[iev, :, 1], X[iev, :, 2], marker=\"o\", color=\"red\", s=2.0)\n",
    "plt.scatter(y[iev][ymsk][:, 1], y[iev][ymsk][:, 2], marker=\"s\", color=\"blue\", s=10*y[iev][ymsk][:, 0], alpha=0.2)\n",
    "plt.title(\"Input set (no edges)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "champion-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Net(3).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iraqi-withdrawal",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compact-gardening",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xt = torch.from_numpy(X).float()\n",
    "yt = torch.from_numpy(y).float()\n",
    "\n",
    "for epoch in range(100):\n",
    "    # zero the parameter gradients\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # forward + backward + optimize\n",
    "    outputs, dms = net(Xt)\n",
    "    loss = criterion(outputs, yt[:, :, 0:1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # print statistics\n",
    "    running_loss = loss.item()\n",
    "    print(running_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "italic-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm = dms[0].coalesce().to_dense().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternative-advocate",
   "metadata": {},
   "outputs": [],
   "source": [
    "msk = X[0, :, 0] == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "biblical-chair",
   "metadata": {},
   "outputs": [],
   "source": [
    "dm[msk, :] = 0\n",
    "dm[:, msk] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aggregate-presentation",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.imshow(dm[:1000, :1000], cmap=\"Blues\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = np.where(dm>0)\n",
    "edges = np.stack([rows, cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confirmed-quest",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_edges = np.random.permutation(edges.shape[1])[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-spelling",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(X[0, ~msk, 1], X[0, ~msk, 2], marker=\"o\", color=\"red\", s=2.0)\n",
    "\n",
    "plt.plot(\n",
    "    X[0, edges[:, random_edges], 1],\n",
    "    X[0, edges[:, random_edges], 2],\n",
    "    linestyle=\"-\",\n",
    "    marker=\"o\", color=\"black\", markerfacecolor=\"red\", markeredgecolor=\"red\", markersize=2.0, lw=0.1\n",
    ");\n",
    "plt.xlim(-1,1)\n",
    "plt.ylim(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "former-duplicate",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
