{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bee6575",
   "metadata": {},
   "source": [
    "**Notebook used to make particle-level eff/fakerates split by detector region**\n",
    "\n",
    "- Stacked histograms\n",
    "- Particle pT, eta, phi\n",
    "- Efficiency and Fake rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb9aad-701c-4176-b34c-b607bce7479b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys, glob\n",
    "import pickle as pkl\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import vector\n",
    "import numpy as np\n",
    "vector.register_awkward()\n",
    "\n",
    "import boost_histogram as bh\n",
    "import numba\n",
    "import mplhep\n",
    "import sklearn\n",
    "import sklearn.metrics\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle\n",
    "import tqdm\n",
    "\n",
    "mplhep.set_style(mplhep.styles.CMS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef08965d-0d4f-4cad-bce4-2ab0b7283e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path += [\"../../mlpf/plotting//\"]\n",
    "from plot_utils import EVALUATION_DATASET_NAMES, experiment_label\n",
    "from plot_utils import SAMPLE_LABEL_CMS, pid_to_text, EXPERIMENT_LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404be348",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_label(ax, sample, additional_text=\"\", x=0.03, y=0.97, fontsize=20):\n",
    "    text = EVALUATION_DATASET_NAMES[sample]\n",
    "    plt.text(x, y, text + additional_text, ha=\"left\", va=\"top\", transform=ax.transAxes, fontsize=fontsize)\n",
    "\n",
    "def cms_label(ax):\n",
    "    return experiment_label(ax, experiment=\"CMS\", tag1=\" Simulation Preliminary\", tag2=\"Run 3 (14 TeV)\", x1=0.13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04809506-6a94-45f1-90a5-fb823d33bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def deltaphi(phi1, phi2):\n",
    "    diff = phi1 - phi2\n",
    "    return np.arctan2(np.sin(diff), np.cos(diff))\n",
    "\n",
    "@numba.njit\n",
    "def deltar(eta1, phi1, eta2, phi2):\n",
    "    deta = eta1 - eta2\n",
    "    dphi = deltaphi(phi1, phi2)\n",
    "    return np.sqrt(deta**2 + dphi**2)\n",
    "\n",
    "@numba.njit\n",
    "def match_particles(eta1, eta2, phi1, phi2, deltaR_cut):\n",
    "    nev = len(eta1)\n",
    "    ptcl_inds_1_ev = []\n",
    "    ptcl_inds_2_ev = []\n",
    "    best_drs_ev = []\n",
    "    for iev in range(nev):\n",
    "        ptcl_inds_1 = []\n",
    "        ptcl_inds_2 = []\n",
    "        best_drs = []\n",
    "\n",
    "        # loop over the first collection\n",
    "        pfs_used = np.zeros(len(eta2[iev]))\n",
    "        for ip1 in range(len(eta1[iev])):\n",
    "            # compute deltaR from this particle to all particles in the other collection\n",
    "            drs = 999*np.ones(len(eta2[iev]), dtype=np.float64)\n",
    "\n",
    "            # loop over the second collection\n",
    "            for ip2 in range(len(eta2[iev])):\n",
    "                if pfs_used[ip2]==1:\n",
    "                    continue\n",
    "                _eta1 = eta1[iev][ip1]\n",
    "                _eta2 = eta2[iev][ip2]\n",
    "                _phi1 = phi1[iev][ip1]\n",
    "                _phi2 = phi2[iev][ip2]\n",
    "\n",
    "                dr = deltar(_eta1, _phi1, _eta2, _phi2)\n",
    "                drs[ip2] = dr\n",
    "\n",
    "            if len(drs) > 0:\n",
    "                # find closest match to this particle\n",
    "                min_idx_dr = np.argmin(drs)\n",
    "\n",
    "                # has to be closer than the deltaR_cut\n",
    "                if drs[min_idx_dr] < deltaR_cut:\n",
    "                    ptcl_inds_1.append(ip1)\n",
    "                    ptcl_inds_2.append(min_idx_dr)\n",
    "                    best_drs.append(drs[min_idx_dr])\n",
    "                    pfs_used[min_idx_dr] = 1\n",
    "                \n",
    "        ptcl_inds_1_ev.append(ptcl_inds_1)\n",
    "        ptcl_inds_2_ev.append(ptcl_inds_2)\n",
    "        best_drs_ev.append(best_drs)\n",
    "    return ptcl_inds_1_ev, ptcl_inds_2_ev, best_drs_ev\n",
    "\n",
    "def sum_overflow_into_last_bin(all_values):\n",
    "    values = all_values[1:-1]\n",
    "    values[-1] = values[-1] + all_values[-1]\n",
    "    values[0] = values[0] + all_values[0]\n",
    "    return values\n",
    "    \n",
    "def to_bh(data, bins, cumulative=False):\n",
    "    h1 = bh.Histogram(bh.axis.Variable(bins))\n",
    "    h1.fill(data)\n",
    "    if cumulative:\n",
    "        h1[:] = np.sum(h1.values()) - np.cumsum(h1)\n",
    "    h1[:] = sum_overflow_into_last_bin(h1.values(flow=True)[:])\n",
    "    return h1\n",
    "\n",
    "def binom_error(n_sig, n_tot):\n",
    "    \"\"\"\n",
    "    for an efficiency = nSig/nTrueSig or purity = nSig / (nSig + nBckgrd), this function calculates the\n",
    "    standard deviation according to http://arxiv.org/abs/physics/0701199 .\n",
    "    \"\"\"\n",
    "    variance = np.where(\n",
    "        n_tot > 0, (n_sig + 1) * (n_sig + 2) / ((n_tot + 2) * (n_tot + 3)) - (n_sig + 1) ** 2 / ((n_tot + 2) ** 2), 0\n",
    "    )\n",
    "    return np.sqrt(variance)\n",
    "\n",
    "def midpoints(x):\n",
    "    return (x[1:] + x[:-1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4ee8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cms\"\n",
    "\n",
    "save_as = {\n",
    "    \"cms_pf_qcd_nopu\": \"QCD_noPU_13p6\",\n",
    "    \"cms_pf_ttbar_nopu\": \"TTbar_noPU_13p6\",\n",
    "}\n",
    "\n",
    "# sample = \"cms_pf_ttbar_nopu\"\n",
    "sample = \"cms_pf_qcd_nopu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abd5ec4-baa0-4896-bc03-d9dd72165e18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# PDG IDs of neutrinos\n",
    "vELE_PDGID = 12\n",
    "vMU_PDGID  = 14\n",
    "vTAU_PDGID = 16\n",
    "\n",
    "def fix_ak(arr):\n",
    "    # replace None with empty list\n",
    "    return ak.Array([x if x is not None else [] for x in arr])\n",
    "\n",
    "def process_file(fn):\n",
    "    # Load events\n",
    "    with open(fn, \"rb\") as f:\n",
    "        events = ak.Array(pkl.load(f))\n",
    "    gen = events[\"packedGenParticles\"]\n",
    "    pf  = events[\"packedPFCandidates\"]\n",
    "\n",
    "    # Compute masks\n",
    "    status = gen[\"status\"]\n",
    "    pdgId  = gen[\"pdgId\"]\n",
    "    mask_final = (status == 1)\n",
    "    mask_nu    = (abs(pdgId) == vELE_PDGID) | \\\n",
    "                 (abs(pdgId) == vMU_PDGID)  | \\\n",
    "                 (abs(pdgId) == vTAU_PDGID)\n",
    "    mask = mask_final & ~mask_nu\n",
    "\n",
    "    # Slice and zip\n",
    "    sliced = {\n",
    "        \"GenCands_pt\":    gen.pt[mask],\n",
    "        \"GenCands_eta\":   gen.eta[mask],\n",
    "        \"GenCands_phi\":   gen.phi[mask],\n",
    "        \"GenCands_pdgId\": gen.pdgId[mask],\n",
    "        \"PFCands_pt\":     pf.pt,\n",
    "        \"PFCands_eta\":    pf.eta,\n",
    "        \"PFCands_phi\":    pf.phi,\n",
    "        \"PFCands_pdgId\":  pf.pdgId,\n",
    "    }\n",
    "    return ak.zip(sliced, depth_limit=1)\n",
    "\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def load_multiprocess(files, max_workers=None):\n",
    "    with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "        results = list(tqdm.tqdm(executor.map(process_file, files), total=len(files)))\n",
    "    successful_results = [r for r in results if r is not None]\n",
    "\n",
    "    return ak.concatenate(successful_results)\n",
    "\n",
    "def load_singleprocess(files):\n",
    "    results = []\n",
    "    for fn in tqdm.tqdm(files):\n",
    "        try:\n",
    "            ret = process_file(fn)\n",
    "            results.append(ret)\n",
    "        except Exception as e:\n",
    "            print(\"could not process \" + fn)\n",
    "    return ak.concatenate(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e10a64b-dc6f-45c0-9649-f0f08aa936b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_mlpf = f\"/eos/user/j/jpata/mlpf/results/cms/CMSSW_15_0_5_mlpf_v2.5.0_p01_f8ae2f_test/cuda_False/{save_as[sample]}_mlpfpu/step3_MINI_*.pkl\"\n",
    "path_pf = f\"/eos/user/j/jpata/mlpf/results/cms/CMSSW_15_0_5_mlpf_v2.5.0_p01_f8ae2f_test/cuda_False/{save_as[sample]}_pf/step3_MINI_*.pkl\"\n",
    "\n",
    "# mlpf\n",
    "files = glob.glob(path_mlpf)\n",
    "files = files[:1000]\n",
    "# data_mlpf =  load_multiprocess([fn for fn in files], 16)\n",
    "data_mlpf =  load_singleprocess([fn for fn in files])\n",
    "\n",
    "# pf\n",
    "files = glob.glob(path_pf)\n",
    "files = files[:1000]\n",
    "# data_pf =  load_multiprocess([fn for fn in files], 16)\n",
    "data_pf =  load_singleprocess([fn for fn in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f777400-21c0-4ff5-aaf7-0090998388de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import particle\n",
    "from particle import Particle\n",
    "from particle import PDGID # https://github.com/scikit-hep/particle\n",
    "\n",
    "import numba\n",
    "from numba import njit\n",
    "from numba.typed import Dict\n",
    "from numba.core import types\n",
    "\n",
    "@numba.njit\n",
    "def get_charge_numba(pids, pid_to_charge_numbadict):\n",
    "    ret = np.zeros(len(pids))\n",
    "    for i in range(len(pids)):\n",
    "        ret[i] = pid_to_charge_numbadict[pids[i]]\n",
    "    return ret\n",
    "    \n",
    "def get_charge_array(pdgids):\n",
    "    pids_uniq = np.unique(pdgids)\n",
    "    pid_to_charge = {\n",
    "        pid: Particle.from_pdgid(pid).charge for pid in pids_uniq\n",
    "    }\n",
    "    \n",
    "    pid_to_charge_numbadict = Dict.empty(key_type=types.int64, value_type=types.float64)\n",
    "    for pid, c in pid_to_charge.items():\n",
    "        pid_to_charge_numbadict[pid] = c\n",
    "\n",
    "    ret = get_charge_numba(pdgids, pid_to_charge_numbadict)\n",
    "    return ak.Array(ret)\n",
    "\n",
    "def remap_pid_gen(data):\n",
    "    \"\"\"\n",
    "    GenCands have all sorts of PID so must remap\n",
    "    \"\"\"\n",
    "    pid = np.abs(np.asarray(ak.flatten(data[\"GenCands_pdgId\"])))\n",
    "    \n",
    "    pa = ak.flatten(np.abs(data[\"GenCands_pdgId\"]))\n",
    "    pc = np.abs(get_charge_array(ak.flatten(data[\"GenCands_pdgId\"])))\n",
    "\n",
    "    pid[(pa!=11) & (pa!=13) & (pa!=22) & (pc==1)] = 211\n",
    "    pid[(pa!=11) & (pa!=13) & (pa!=22) & (pc==0)] = 130\n",
    "    data[\"GenCands_pid\"] = ak.unflatten(pid, ak.count(data[\"GenCands_pdgId\"], axis=1))\n",
    "    data[\"PFCands_pid\"] = np.abs(data[\"PFCands_pdgId\"])\n",
    "\n",
    "remap_pid_gen(data_pf)\n",
    "remap_pid_gen(data_mlpf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c1b4aa",
   "metadata": {},
   "source": [
    "# Plot configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696c5900",
   "metadata": {},
   "outputs": [],
   "source": [
    "color_code = {\n",
    "    \"Gen\": \"tab:blue\",\n",
    "    \"PF\": \"tab:orange\",\n",
    "    \"MLPF\": \"tab:red\",\n",
    "}\n",
    "\n",
    "bins_pt = {\n",
    "    \"cms_pf_qcd_nopu\": {\n",
    "        211: np.linspace(0,500,41),\n",
    "        130: np.linspace(0,200,41),\n",
    "        22: np.linspace(0,200,41),\n",
    "        11: np.linspace(0,50,21),\n",
    "        13: np.linspace(0,50,21),\n",
    "    },\n",
    "    \"cms_pf_ttbar_nopu\": {\n",
    "        211: np.linspace(0,60,31),\n",
    "        130: np.linspace(0,40,31),\n",
    "        22: np.linspace(0,40,31),\n",
    "        11: np.linspace(0,100,31),\n",
    "        13: np.linspace(0,100,31),\n",
    "    },  \n",
    "}\n",
    "\n",
    "bins_eta = {\n",
    "    \"cms_pf_qcd_nopu\": {\n",
    "        211: np.linspace(-2.5,2.5,41),\n",
    "        130: np.linspace(-3,3,41),\n",
    "        22: np.linspace(-3,3,41),\n",
    "        11: np.linspace(-2.5,2.5,41),\n",
    "        13: np.linspace(-2.5,2.5,41),\n",
    "    },\n",
    "    \"cms_pf_ttbar_nopu\": {\n",
    "        211: np.linspace(-2.5,2.5,41),\n",
    "        130: np.linspace(-3,3,41),\n",
    "        22: np.linspace(-3,3,41),\n",
    "        11: np.linspace(-2.5,2.5,41),\n",
    "        13: np.linspace(-2.5,2.5,41),\n",
    "    },\n",
    "}\n",
    "\n",
    "bins_phi = {\n",
    "    \"cms_pf_qcd_nopu\": {\n",
    "        211: np.linspace(-3,3,41),\n",
    "        130: np.linspace(-3,3,41),\n",
    "        22: np.linspace(-3,3,41),\n",
    "        11: np.linspace(-3,3,41),\n",
    "        13: np.linspace(-3,3,41),\n",
    "    },\n",
    "    \"cms_pf_ttbar_nopu\": {\n",
    "        211: np.linspace(-3,3,41),\n",
    "        130: np.linspace(-3,3,41),\n",
    "        22: np.linspace(-3,3,41),\n",
    "        11: np.linspace(-3,3,21),\n",
    "        13: np.linspace(-3,3,21),\n",
    "    },  \n",
    "}\n",
    "\n",
    "marker_style = {\n",
    "    'PF': 's',\n",
    "    'MLPF': 'o',\n",
    "}\n",
    "linestyle = {\n",
    "    'Gen': '--',\n",
    "    'PF': ':',\n",
    "    'MLPF': '-',\n",
    "}\n",
    "\n",
    "col_pid = {\n",
    "    211: \"tab:blue\",\n",
    "    130: \"tab:orange\",\n",
    "    22: \"tab:red\",\n",
    "    11: \"tab:green\",\n",
    "    13: \"tab:pink\",    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41630221",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f\"./plots/{save_as[sample]}/particle_eff_fakerate_phasespacesplit\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b57e9f",
   "metadata": {},
   "source": [
    "# Make particle-level plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2870cafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_cuts = [\n",
    "    (0, 1.3), \n",
    "    (1.3, 2.5), \n",
    "    (2.5, 2.7), \n",
    "    (2.7, 3.0),\n",
    "]\n",
    "\n",
    "pt_cuts = [\n",
    "    (0, 3), \n",
    "    (3, 5), \n",
    "    (5, 10), \n",
    "    (10, 20), \n",
    "    (20, 40), \n",
    "    (40, 100), \n",
    "    (100, np.inf),\n",
    "]\n",
    "\n",
    "cut_label = {\n",
    "    \"pt\": {\n",
    "        (0, 3): r\"$p_T < 3$ GeV\",\n",
    "        (3, 5): r\"$3 < p_T < 5$ GeV\",\n",
    "        (5, 10): r\"$5 < p_T < 10$ GeV\",\n",
    "        (10, 20): r\"$10 < p_T < 20$ GeV\",\n",
    "        (20, 40): r\"$20 < p_T < 40$ GeV\",\n",
    "        (40, 100): r\"$40 < p_T < 100$ GeV\",\n",
    "        (100, np.inf): r\"$p_T > 100$ GeV\",\n",
    "    },\n",
    "    \"eta\": {\n",
    "        (0, 1.3): r\"$|\\eta|<1.3$\",\n",
    "        (1.3, 2.5): r\"$1.3 < |\\eta| < 2.5$\",\n",
    "        (2.5, 2.7): r\"$2.5 < |\\eta| < 2.7$\", \n",
    "        (2.7, 3.0): r\"$2.7 < |\\eta| < 3.0$\",\n",
    "    } , \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e7e83",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "bins_pt = {}\n",
    "bins_pt[sample] = {}\n",
    "\n",
    "# must define matching condition\n",
    "dR_cut = 0.15\n",
    "\n",
    "for pid in [\n",
    "    211,\n",
    "    130,\n",
    "#     22,\n",
    "]:\n",
    "\n",
    "    for pt_cut in pt_cuts:\n",
    "\n",
    "        fig, axs = plt.subplots(2, 4, figsize=(28, 12))\n",
    "        axs = axs.flatten()    \n",
    "\n",
    "        for i, eta_cut in enumerate(eta_cuts):\n",
    "            \n",
    "            bins_pt[sample][pid] = np.linspace(pt_cut[0], pt_cut[1], 5) if pt_cut[1] != np.inf else np.linspace(pt_cut[0], 200, 5)\n",
    "            \n",
    "            ################\n",
    "            # define baseline kinematic cuts\n",
    "            msk_pf_gen_pt = (data_pf[\"GenCands_pt\"] > pt_cut[0]) & (data_pf[\"GenCands_pt\"] < pt_cut[1])\n",
    "            msk_pf_gen_eta = (abs(data_pf[\"GenCands_eta\"]) > eta_cut[0]) & (abs(data_pf[\"GenCands_eta\"]) < eta_cut[1])\n",
    "            msk_pf_gen = msk_pf_gen_pt & msk_pf_gen_eta\n",
    "\n",
    "            msk_pf_reco_pt = (data_pf[\"PFCands_pt\"] > pt_cut[0]) & (data_pf[\"PFCands_pt\"] < pt_cut[1])\n",
    "            msk_pf_reco_eta = (abs(data_pf[\"PFCands_eta\"]) > eta_cut[0]) & (abs(data_pf[\"PFCands_eta\"]) < eta_cut[1])\n",
    "            msk_pf_reco = msk_pf_reco_pt & msk_pf_reco_eta\n",
    "\n",
    "            # apply baseline kinematic cuts\n",
    "            eta1 = data_pf[\"GenCands_eta\"][msk_pf_gen]\n",
    "            phi1 = data_pf[\"GenCands_phi\"][msk_pf_gen]\n",
    "\n",
    "            eta2 = data_pf[\"PFCands_eta\"][msk_pf_reco]\n",
    "            phi2 = data_pf[\"PFCands_phi\"][msk_pf_reco]\n",
    "\n",
    "            pf_idx1, pf_idx2, pf_dr = match_particles(eta1, eta2, phi1, phi2, dR_cut)\n",
    "\n",
    "            # define baseline kinematic cuts\n",
    "            msk_mlpf_gen_pt = (data_mlpf[\"GenCands_pt\"] > pt_cut[0]) & (data_mlpf[\"GenCands_pt\"] < pt_cut[1])\n",
    "            msk_mlpf_gen_eta = (abs(data_mlpf[\"GenCands_eta\"]) > eta_cut[0]) & (abs(data_mlpf[\"GenCands_eta\"]) < eta_cut[1])\n",
    "            msk_mlpf_gen = msk_mlpf_gen_pt & msk_mlpf_gen_eta\n",
    "\n",
    "            msk_mlpf_reco_pt = (data_mlpf[\"PFCands_pt\"] > pt_cut[0]) & (data_mlpf[\"PFCands_pt\"] < pt_cut[1])\n",
    "            msk_mlpf_reco_eta = (abs(data_mlpf[\"PFCands_eta\"]) > eta_cut[0]) & (abs(data_mlpf[\"PFCands_eta\"]) < eta_cut[1])\n",
    "            msk_mlpf_reco = msk_mlpf_reco_pt & msk_mlpf_reco_eta\n",
    "\n",
    "            # apply baseline kinematic cuts\n",
    "            eta1 = data_mlpf[\"GenCands_eta\"][msk_mlpf_gen]\n",
    "            phi1 = data_mlpf[\"GenCands_phi\"][msk_mlpf_gen]\n",
    "\n",
    "            eta2 = data_mlpf[\"PFCands_eta\"][msk_mlpf_reco]\n",
    "            phi2 = data_mlpf[\"PFCands_phi\"][msk_mlpf_reco]\n",
    "\n",
    "            mlpf_idx1, mlpf_idx2, mlpf_dr = match_particles(eta1, eta2, phi1, phi2, dR_cut)\n",
    "\n",
    "            ################\n",
    "            # plotting below\n",
    "\n",
    "            #pick genparticles, and genparticles matched to reco\n",
    "            h_pf_gen =            to_bh(ak.flatten(data_pf[\"GenCands_pt\"][msk_pf_gen][data_pf[\"GenCands_pid\"][msk_pf_gen]==pid]), bins=bins_pt[sample][pid])\n",
    "            h_pf_gen_matched =    to_bh(ak.flatten(data_pf[\"GenCands_pt\"][msk_pf_gen][pf_idx1][data_pf[\"GenCands_pid\"][msk_pf_gen][pf_idx1]==pid]), bins=bins_pt[sample][pid])\n",
    "\n",
    "            #pick recoparticles, and recoparticles matched to gen\n",
    "            h_pf_reco =           to_bh(ak.flatten(data_pf[\"PFCands_pt\"][msk_pf_reco][data_pf[\"PFCands_pid\"][msk_pf_reco]==pid]), bins=bins_pt[sample][pid])\n",
    "            h_pf_reco_matched =   to_bh(ak.flatten(data_pf[\"PFCands_pt\"][msk_pf_reco][pf_idx2][data_pf[\"PFCands_pid\"][msk_pf_reco][pf_idx2]==pid]), bins=bins_pt[sample][pid])\n",
    "\n",
    "            #repeat for mlpf\n",
    "            h_mlpf_gen =          to_bh(ak.flatten(data_mlpf[\"GenCands_pt\"][msk_mlpf_gen][data_mlpf[\"GenCands_pid\"][msk_mlpf_gen]==pid]), bins=bins_pt[sample][pid])\n",
    "            h_mlpf_gen_matched =  to_bh(ak.flatten(data_mlpf[\"GenCands_pt\"][msk_mlpf_gen][mlpf_idx1][data_mlpf[\"GenCands_pid\"][msk_mlpf_gen][mlpf_idx1]==pid]), bins=bins_pt[sample][pid])\n",
    "\n",
    "            h_mlpf_reco =         to_bh(ak.flatten(data_mlpf[\"PFCands_pt\"][msk_mlpf_reco][data_mlpf[\"PFCands_pid\"][msk_mlpf_reco]==pid]), bins=bins_pt[sample][pid])\n",
    "            h_mlpf_reco_matched = to_bh(ak.flatten(data_mlpf[\"PFCands_pt\"][msk_mlpf_reco][mlpf_idx2][data_mlpf[\"PFCands_pid\"][msk_mlpf_reco][mlpf_idx2]==pid]), bins=bins_pt[sample][pid])\n",
    "\n",
    "            #eff: fraction of all gen that were reconstructed\n",
    "            heff_pf = h_pf_gen_matched/h_pf_gen\n",
    "            #fake: fraction of all reco that were matched to gen\n",
    "            hfake_pf = (h_pf_reco - h_pf_reco_matched)/h_pf_reco\n",
    "\n",
    "            heff_mlpf = h_mlpf_gen_matched/h_mlpf_gen\n",
    "            hfake_mlpf = (h_mlpf_reco - h_mlpf_reco_matched)/h_mlpf_reco\n",
    "\n",
    "            #eff plot\n",
    "            axs[i].errorbar(\n",
    "                midpoints(heff_pf.axes[0].edges), heff_pf.values(), binom_error(h_pf_gen_matched.values(), h_pf_gen.values()), marker=\".\", label=\"PF\", linestyle=\"--\", color=color_code[\"PF\"],\n",
    "            )\n",
    "\n",
    "            axs[i].errorbar(\n",
    "                midpoints(heff_mlpf.axes[0].edges), heff_mlpf.values(), binom_error(h_mlpf_gen_matched.values(), h_mlpf_gen.values()), marker=\".\", label=\"MLPF\", color=color_code[\"MLPF\"],\n",
    "            )\n",
    "            \n",
    "            axs[i].set_ylim(0, 1.3)\n",
    "            axs[i].set_title(cut_label[\"eta\"][eta_cut], pad=15)\n",
    "            axs[i].set_ylabel(\"Efficiency\", fontsize=22)\n",
    "            axs[i].set_xlabel(\"$p_T^{gen}$ (GeV)\", fontsize=22)\n",
    "            axs[i].legend(fontsize=22, loc=\"upper right\",  bbox_to_anchor=(1, 1 - 0.1))\n",
    "            sample_label(axs[i], sample, additional_text=\", no PU\", fontsize=22)\n",
    "\n",
    "            ### Fake Rate\n",
    "            axs[i + 4].errorbar(\n",
    "                midpoints(hfake_pf.axes[0].edges), hfake_pf.values(),\n",
    "                binom_error(h_pf_reco_matched.values(), h_pf_reco.values()),\n",
    "                marker=\".\", label=\"PF\", linestyle=\"--\", color=color_code[\"PF\"]\n",
    "            )\n",
    "            axs[i + 4].errorbar(\n",
    "                midpoints(hfake_mlpf.axes[0].edges), hfake_mlpf.values(),\n",
    "                binom_error(h_mlpf_reco_matched.values(), h_mlpf_reco.values()),\n",
    "                marker=\".\", label=\"MLPF\", color=color_code[\"MLPF\"]\n",
    "            )\n",
    "            axs[i + 4].set_ylim(0, 1.0)\n",
    "            axs[i + 4].set_title(cut_label[\"eta\"][eta_cut], pad=15)\n",
    "            axs[i + 4].set_ylabel(\"Fake rate\", fontsize=22)\n",
    "            axs[i + 4].set_xlabel(\"$p_T^{reco}$ (GeV)\", fontsize=22)\n",
    "            axs[i + 4].legend(fontsize=22, loc=\"upper right\", bbox_to_anchor=(1, 1 - 0.1))\n",
    "\n",
    "            sample_label(axs[i + 4], sample, additional_text=\", no PU\", fontsize=22)\n",
    "\n",
    "        fig.suptitle(f\"{pid_to_text[pid]}, {cut_label['pt'][pt_cut]}\", fontsize=45)\n",
    "\n",
    "        fig.subplots_adjust(wspace=0.25, hspace=0.4)\n",
    "        plt.savefig(f\"./plots/{save_as[sample]}/particle_eff_fakerate_phasespacesplit/{pid}_pt{pt_cut[0]}to{pt_cut[1]}.pdf\")        \n",
    "            \n",
    "#         break\n",
    "#     break"
   ]
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
