{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8e7ac6c-997d-4ecf-9a6f-b96f593713dc",
   "metadata": {},
   "source": [
    "This notebook is responsible for exporting the MLPF trained model from pytorch to ONNX."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5a5a5d-8f56-45a8-b649-7933a777f82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnxscript\n",
    "# !pip install onnxconverter-common"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52b47c-e6c7-4399-9686-e240da62fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import copy\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "import math\n",
    "\n",
    "import numba\n",
    "import awkward\n",
    "import vector\n",
    "import fastjet\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import mplhep\n",
    "\n",
    "import boost_histogram as bh\n",
    "import mplhep\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "import onnxscript\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from onnxconverter_common import float16\n",
    "from onnxscript.function_libs.torch_lib.tensor_typing import TFloat\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "import mlpf\n",
    "from mlpf.model.mlpf import MLPF\n",
    "from mlpf.model.utils import unpack_predictions, unpack_target\n",
    "from mlpf.jet_utils import match_jets, to_p4_sph\n",
    "from mlpf.plotting.plot_utils import cms_label, sample_label, ELEM_NAMES_CMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ac816c-5c34-4c13-8598-67f72d564fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplhep.style.use(\"CMS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba2bd59-4edb-4603-99e5-1d1d94e89f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which onnxruntime we are using. For CUDA, we must use onnxruntime-gpu (not onnxruntime)\n",
    "rt.__path__, rt.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f88f00e4-bd83-4eb0-a4c6-12d01beadc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8413bda-1e12-44fd-968e-590806f3da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# contrib op: https://github.com/microsoft/onnxruntime/blob/main/docs/ContribOperators.md#commicrosoftmultiheadattention\n",
    "# CMSSW ONNXRuntime version: https://github.com/cms-sw/cmsdist/blob/REL/CMSSW_14_1_0_pre3/el9_amd64_gcc12/onnxruntime.spec\n",
    "# ONNXRuntime compatiblity table: https://onnxruntime.ai/docs/reference/compatibility.html\n",
    "\n",
    "#with pytorch 2.5.0, we should use at least opset 20 (previous opsets did not work)\n",
    "from onnxscript import opset20 as op\n",
    "opset_version = 20\n",
    "\n",
    "custom_opset = onnxscript.values.Opset(domain=\"onnx-script\", version=1)\n",
    "msft_op = onnxscript.values.Opset(\"com.microsoft\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2dca97d-62ca-42df-a956-8b43664b441c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls /home/joosep/particleflow/experiments/pyg-cms_20250722_101813_274478/checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d0792-ec61-4168-802c-7e914f1d449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfds datasets are here:\n",
    "data_dir = \"/scratch/persistent/joosep/tensorflow_datasets/\"\n",
    "dataset = \"cms_pf_ttbar\"\n",
    "\n",
    "#model checkpoints are here:\n",
    "outdir = \"/home/joosep/particleflow/experiments/pyg-cms_20250722_101813_274478/\"\n",
    "\n",
    "#Load model weights from existing training\n",
    "model_state = torch.load(\n",
    "    outdir + \"/checkpoints/checkpoint-10-3.812332.pth\", map_location=torch.device(\"cpu\"), weights_only=True\n",
    ")\n",
    "with open(f\"{outdir}/model_kwargs.pkl\", \"rb\") as f:\n",
    "    model_kwargs = pkl.load(f)\n",
    "\n",
    "\n",
    "#this is needed to configure com.microsoft.MultiHeadAttention\n",
    "NUM_HEADS = model_kwargs[\"num_heads\"]\n",
    "\n",
    "#set this to cuda if you are running the notebook on a GPU, otherwise use cpu\n",
    "torch_device = \"cpu\"\n",
    "if torch_device == \"cpu\":\n",
    "    model_kwargs[\"attention_type\"] = \"math\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac122980-f83f-4d7e-a6c3-6d75843d5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPF(**model_kwargs, use_simplified_attention=False, export_onnx_fused=False, save_attention=True)\n",
    "model.eval()\n",
    "model.load_state_dict(model_state[\"model_state_dict\"], strict=False)\n",
    "model = model.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19c4ac-e579-46c2-86d0-6f664f4b8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple_unfused = MLPF(**model_kwargs, use_simplified_attention=True, export_onnx_fused=False)\n",
    "model_simple_unfused.eval()\n",
    "model_simple_unfused.load_state_dict(model_state[\"model_state_dict\"], strict=False)\n",
    "model_simple_unfused = model_simple_unfused.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb626fe-be67-44ee-b65f-d983792af3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple_fused = MLPF(**model_kwargs, use_simplified_attention=True, export_onnx_fused=True)\n",
    "model_simple_fused.eval()\n",
    "model_simple_fused.load_state_dict(model_state[\"model_state_dict\"], strict=False)\n",
    "model_simple_fused = model_simple_fused.to(device=torch_device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befeb322-86a9-470c-ba31-135737425e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -f *.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a80773b-feff-400f-adab-aa01fbf5ec10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the values in here are not important, it just needs some kind of shapes\n",
    "dummy_features = torch.randn(1, 256, model_kwargs[\"input_dim\"]).float()\n",
    "dummy_mask = (torch.randn(1, 256)>0.5).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64c36dd-1ebd-40d6-80c4-a866e3660663",
   "metadata": {},
   "outputs": [],
   "source": [
    "(model(dummy_features, dummy_mask)[1] - model_simple_unfused(dummy_features, dummy_mask)[1]).abs().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d13de45-8d20-442d-96ac-f5b8cc4d9fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#export the ONNX model with naive (unfused) attention\n",
    "torch.onnx.export(\n",
    "    model_simple_unfused,\n",
    "    (dummy_features, dummy_mask),\n",
    "    \"test_fp32_unfused.onnx\",\n",
    "    opset_version=opset_version,\n",
    "    verbose=False,\n",
    "    input_names=[\n",
    "        \"Xfeat_normed\", \"mask\",\n",
    "    ],\n",
    "    output_names=[\"bid\", \"id\", \"momentum\", \"pu\"],\n",
    "    dynamic_axes={\n",
    "        \"Xfeat_normed\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"mask\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"bid\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"id\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"momentum\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"pu\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecf124-8610-476b-9a08-94a3513d1074",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#register our custom op that calls out to the fast MultiHeadAttention implementation\n",
    "@onnxscript.script(custom_opset)\n",
    "def SDPA(\n",
    "    query: TFloat,\n",
    "    key: TFloat,\n",
    "    value: TFloat,\n",
    ") -> TFloat:\n",
    "\n",
    "    # Unlike pytorch scaled_dot_product_attention,\n",
    "    # the input here MUST BE (batch, seq_len, num_head*head_dim).\n",
    "    # Also, for the op to be fast on GPU, it needs to run in float16.\n",
    "    query = op.Cast(query, to=onnx.TensorProto.FLOAT16)\n",
    "    key = op.Cast(key, to=onnx.TensorProto.FLOAT16)\n",
    "    value = op.Cast(value, to=onnx.TensorProto.FLOAT16)\n",
    "    output, _, _ = msft_op.MultiHeadAttention(query, key, value, num_heads=NUM_HEADS)\n",
    "    output = op.Cast(output, to=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# setType API provides shape/type to ONNX shape/type inference\n",
    "# function signature must match pytorch aten::scaled_dot_product_attention from\n",
    "# https://github.com/pytorch/pytorch/blob/16676fd17b10b06e692656bbba8db5e0d6052a20/aten/src/ATen/native/transformers/attention.cpp#L699\n",
    "def custom_scaled_dot_product_attention(\n",
    "    g, query: TFloat, key: TFloat, value: TFloat, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None, enable_gqa=False\n",
    "):\n",
    "    return g.onnxscript_op(SDPA, query, key, value).setType(query.type())\n",
    "\n",
    "\n",
    "#the warning 'MultiHeadAttention' is not a known op in 'com.microsoft' is not actually important\n",
    "print(\"registering custom op for scaled_dot_product_attention\")\n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::scaled_dot_product_attention\",\n",
    "    symbolic_fn=custom_scaled_dot_product_attention,\n",
    "    opset_version=opset_version,\n",
    ")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_simple_fused,\n",
    "    (dummy_features, dummy_mask),\n",
    "    \"test_fp32_fused.onnx\",\n",
    "    opset_version=opset_version,\n",
    "    verbose=False,\n",
    "    input_names=[\n",
    "        \"Xfeat_normed\", \"mask\",\n",
    "    ],\n",
    "    output_names=[\"bid\", \"id\", \"momentum\", \"pu\"],\n",
    "    dynamic_axes={\n",
    "        \"Xfeat_normed\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"mask\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"bid\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"id\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"momentum\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"pu\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e50424-5a61-4c9c-8f5b-6df132dd1768",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Available ONNX runtime providers:\", rt.get_available_providers())\n",
    "sess_options = rt.SessionOptions()\n",
    "sess_options.intra_op_num_threads = 32  # need to explicitly set this to get rid of onnxruntime error\n",
    "\n",
    "sess_options.log_severity_level = 1\n",
    "sess_options.graph_optimization_level = rt.GraphOptimizationLevel.ORT_ENABLE_EXTENDED\n",
    "\n",
    "execution_provider = \"CPUExecutionProvider\"\n",
    "if torch_device == \"cuda\":\n",
    "    execution_provider = \"CUDAExecutionProvider\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5bf9b61-6e80-4b79-9526-d545294e3b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_sess_unfused = rt.InferenceSession(\"test_fp32_unfused.onnx\", sess_options, providers=[execution_provider])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9264eb8e-bd01-482c-a9c9-de6c7587e58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_sess_fused = rt.InferenceSession(\"test_fp32_fused.onnx\", sess_options, providers=[execution_provider])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc3e15-be3f-4dcd-9f31-7f6e1eb82561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffs_vec(pred_reference, pred_test):\n",
    "    diffs = [torch.mean(torch.abs(torch.flatten(pred_reference[i]-pred_test[i]))).item() for i in range(len(pred_test))]\n",
    "    return diffs\n",
    "\n",
    "#cluster particles to jets, return jet pt\n",
    "def particles_to_jets(pred, mask):\n",
    "    jetdef = fastjet.JetDefinition(fastjet.antikt_algorithm, 0.4)\n",
    "    ypred = unpack_predictions(pred)\n",
    "    for k, v in ypred.items():\n",
    "        ypred[k] = v[mask].detach().cpu().contiguous().numpy()\n",
    "    \n",
    "    counts = torch.sum(mask, axis=1).cpu().numpy()\n",
    "    clsid = awkward.unflatten(ypred[\"cls_id\"], counts)\n",
    "    msk = clsid != 0\n",
    "    p4 = awkward.unflatten(ypred[\"p4\"], counts)\n",
    "    \n",
    "    vec = vector.awk(\n",
    "        awkward.zip(\n",
    "            {\n",
    "                \"pt\": p4[msk][:, :, 0],\n",
    "                \"eta\": p4[msk][:, :, 1],\n",
    "                \"phi\": p4[msk][:, :, 2],\n",
    "                \"e\": p4[msk][:, :, 3],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    cluster = fastjet.ClusterSequence(vec.to_xyzt(), jetdef)\n",
    "    jets = cluster.inclusive_jets(min_pt=3)\n",
    "    return jets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff46497-e83d-48ec-99e6-140ed7047111",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over the dataset, run the 4 different models, save outputs\n",
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds = builder.as_data_source(split=\"train\")\n",
    "\n",
    "max_events = 10\n",
    "events_per_batch = 1\n",
    "inds = range(0, max_events, events_per_batch)\n",
    "\n",
    "jets_mlpf = []\n",
    "jets_mlpf_simple = []\n",
    "jets_onnx_unfused = []\n",
    "jets_onnx_fused = []\n",
    "\n",
    "model = model.to(torch_device)\n",
    "\n",
    "preds = []\n",
    "preds_onnx_fused = []\n",
    "X_feat_list = []\n",
    "y_target_list = []\n",
    "for ind in tqdm(inds):\n",
    "    ds_elems = [ds[i] for i in range(ind,ind+events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32).to(torch_device) for elem in ds_elems]\n",
    "    y_targets = [torch.tensor(elem[\"ytarget\"]).to(torch.float32).to(torch_device) for elem in ds_elems]\n",
    "    X_feat_list += X_features\n",
    "    y_target_list += y_targets\n",
    "\n",
    "    #batch the data into [batch_size, num_elems, num_features]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True).contiguous()\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True).contiguous()\n",
    "    # print(\"batch\", ind, X_features_padded.shape)\n",
    "    mask = X_features_padded[:, :, 0]!=0\n",
    "    mask_f = mask.float()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # print(\"running base pytorch model\")\n",
    "        pred = model(X_features_padded.to(torch_device), mask.to(torch_device))\n",
    "        pred = tuple(pred[x].cpu() for x in range(len(pred)))\n",
    "        preds.append(pred)\n",
    "\n",
    "    j0 = particles_to_jets(pred, mask.cpu())\n",
    "    jets_mlpf.append(j0)\n",
    "\n",
    "    # print(\"running ONNX unfused model\")\n",
    "    pred_onnx_unfused = onnx_sess_unfused.run([\"bid\", \"id\", \"momentum\", \"pu\"], {\"Xfeat_normed\": X_features_padded.cpu().numpy(), \"mask\": mask_f.cpu().numpy()})\n",
    "    pred_onnx_unfused = tuple(torch.tensor(p) for p in pred_onnx_unfused)\n",
    "    j2 = particles_to_jets(pred_onnx_unfused, mask.cpu())\n",
    "    jets_onnx_unfused.append(j2)\n",
    "\n",
    "    # print(\"running ONNX fused model\")\n",
    "    pred_onnx_fused = onnx_sess_fused.run([\"bid\", \"id\", \"momentum\", \"pu\"], {\"Xfeat_normed\": X_features_padded.cpu().numpy(), \"mask\": mask_f.cpu().numpy()})\n",
    "    pred_onnx_fused = tuple(torch.tensor(p) for p in pred_onnx_fused)\n",
    "    preds_onnx_fused.append(pred_onnx_fused)\n",
    "    \n",
    "    j3 = particles_to_jets(pred_onnx_fused, mask.cpu())\n",
    "    jets_onnx_fused.append(j3)\n",
    "\n",
    "    for conv in model.conv_id + model.conv_reg:\n",
    "        conv.att_mat_idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1435d5e-efba-44f7-aa29-54481d8490dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_overflow_into_last_bin(all_values):\n",
    "    values = all_values[1:-1]\n",
    "    values[-1] = values[-1] + all_values[-1]\n",
    "    values[0] = values[0] + all_values[0]\n",
    "    return values\n",
    "\n",
    "def to_bh(data, bins, cumulative=False):\n",
    "    h1 = bh.Histogram(bh.axis.Variable(bins))\n",
    "    h1.fill(data)\n",
    "    if cumulative:\n",
    "        h1[:] = np.sum(h1.values()) - np.cumsum(h1)\n",
    "    h1[:] = sum_overflow_into_last_bin(h1.values(flow=True)[:])\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441021e7-c1da-4459-a7ed-ebf85be4c0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#There can be cases where different inference modes produce very slightly different numbers of jets due to floating point differences.\n",
    "#Therefore, we match jet pairs based on delta-R, and compare the pT of matched jets.\n",
    "match_inds1, match_inds2 = match_jets(to_p4_sph(awkward.concatenate(jets_mlpf)), to_p4_sph(awkward.concatenate(jets_onnx_unfused)), 0.001)\n",
    "match_inds3, match_inds4 = match_jets(to_p4_sph(awkward.concatenate(jets_mlpf)), to_p4_sph(awkward.concatenate(jets_onnx_fused)), 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46fcfdd-087d-4e22-9243-9d84f25c169b",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.logspace(0, 2, 200)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist2d(\n",
    "    awkward.to_numpy(awkward.flatten(awkward.concatenate(jets_mlpf)[match_inds1].pt)),\n",
    "    awkward.to_numpy(awkward.flatten(awkward.concatenate(jets_onnx_unfused)[match_inds2].pt)),\n",
    "    bins=b,\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    cmap=\"Reds\"\n",
    ");\n",
    "plt.xlabel(\"jet $p_{\\mathrm{T,pytorch}}$\")\n",
    "plt.ylabel(\"jet $p_{\\mathrm{T,pytorch,simple}}$\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f501b02f-ca20-41a9-ae94-e6857854e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.logspace(0, 2, 200)\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist2d(\n",
    "    awkward.to_numpy(awkward.flatten(awkward.concatenate(jets_mlpf)[match_inds3].pt)),\n",
    "    awkward.to_numpy(awkward.flatten(awkward.concatenate(jets_onnx_fused)[match_inds4].pt)),\n",
    "    bins=b,\n",
    "    norm=mpl.colors.LogNorm(),\n",
    "    cmap=\"Reds\"\n",
    ");\n",
    "plt.xlabel(\"jet $p_{\\mathrm{T,pytorch,simple}}$\")\n",
    "plt.ylabel(\"jet $p_{\\mathrm{T,ONNX}}$\")\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9971b29-2efa-4dba-a5e9-46369a6919a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(0.9,1.1, 500)\n",
    "plt.figure(figsize=(10, 10))\n",
    "ax = plt.axes()\n",
    "plt.hist(\n",
    "    awkward.flatten(awkward.concatenate(jets_mlpf)[match_inds3].pt/awkward.concatenate(jets_onnx_fused)[match_inds4].pt),\n",
    "    bins=b, histtype=\"step\");\n",
    "plt.yscale(\"log\")\n",
    "plt.xlabel(\"jet $p_{\\mathrm{T,ONNX,fused}}/p_{\\mathrm{T,pytorch}}$\")\n",
    "plt.ylabel(\"Number of matched jets\")\n",
    "cms_label(ax)\n",
    "sample_label(ax, dataset)\n",
    "plt.savefig(\"pytorch_onnx_jet_ratio.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026531f-07d7-4451-be73-caf68960a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (a0, a1) = plt.subplots(2, 1, gridspec_kw={\"height_ratios\": [4, 1]}, sharex=True, figsize=(10, 10))\n",
    "\n",
    "plt.sca(a0)\n",
    "\n",
    "b = np.logspace(0,2,101)\n",
    "h0 = to_bh(awkward.flatten(awkward.concatenate(jets_mlpf).pt), bins=b)\n",
    "h1 = to_bh(awkward.flatten(awkward.concatenate(jets_onnx_unfused).pt), bins=b)\n",
    "h2 = to_bh(awkward.flatten(awkward.concatenate(jets_onnx_fused).pt), bins=b)\n",
    "\n",
    "mplhep.histplot(h0, label=\"pytorch\", lw=0.5, yerr=0)\n",
    "mplhep.histplot(h1, label=\"ONNX, unfused\", lw=0.5, yerr=0)\n",
    "mplhep.histplot(h2, label=\"ONNX, fused\", lw=0.5, yerr=0)\n",
    "\n",
    "plt.legend()\n",
    "plt.yscale(\"log\")\n",
    "plt.xscale(\"log\")\n",
    "plt.ylabel(\"Number of jets\")\n",
    "cms_label(a0)\n",
    "sample_label(a0, dataset)\n",
    "\n",
    "plt.sca(a1)\n",
    "mplhep.histplot(h0/h0, label=\"pytorch\", lw=0.5, yerr=0)\n",
    "mplhep.histplot(h1/h0, label=\"ONNX, fused\", lw=0.5, yerr=0)\n",
    "mplhep.histplot(h2/h0, label=\"ONNX, unfused\", lw=0.5, yerr=0)\n",
    "plt.ylim(0.5, 1.5)\n",
    "plt.xlim(1, 100)\n",
    "plt.ylabel(\"vs. pytorch\")\n",
    "plt.xlabel(\"jet $p_T$ [GeV]\")\n",
    "plt.savefig(\"pytorch_onnx_jet_pt.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca7550-0d14-4d6c-b206-9a4fe98bc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "att_mat_reg2 = np.load(\"attn_conv_reg_2_0.npz\")[\"att\"]\n",
    "plt.imshow(att_mat_reg2[0], cmap=\"hot_r\", norm=matplotlib.colors.LogNorm(vmin=1e-6, vmax=1))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce988bfb-74db-4881-9f6b-dcf1d2ec6b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.manifold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbbc7c5-b3b1-4beb-9027-2f7688560706",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_kwargs[\"num_convs\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60186e3-3801-403b-8b1e-6726ec1425bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#take the intermediate outputs of the first event for all layers\n",
    "att_filenames = (\n",
    "    [\"attn_conv_reg_{}_0\".format(ilayer) for ilayer in range(model_kwargs[\"num_convs\"])] +\n",
    "    [\"attn_conv_id_{}_0\".format(ilayer) for ilayer in range(model_kwargs[\"num_convs\"])] \n",
    "    )\n",
    "\n",
    "\n",
    "#separate elements by type\n",
    "typs = [\n",
    "    1, #track\n",
    "    4,5, #calo\n",
    "    6, #FSG\n",
    "\n",
    "    #HF\n",
    "    8,9,\n",
    "\n",
    "    #don't visualize superclusters and HO for simplicity\n",
    "    #10,11\n",
    "]\n",
    "\n",
    "#take the data for the first event\n",
    "X = X_feat_list[0].numpy()\n",
    "y = y_target_list[0].numpy()\n",
    "\n",
    "energy_marker_sizes = np.linspace(1,30,10)\n",
    "energy_bins = np.logspace(0,3,10)\n",
    "energy_markers = energy_marker_sizes[np.searchsorted(energy_bins, X[:, 5])]\n",
    "\n",
    "fig, axs = plt.subplots(2, model_kwargs[\"num_convs\"], figsize=(5*model_kwargs[\"num_convs\"],2*5))\n",
    "axs = axs.flatten()\n",
    "iattn = 0\n",
    "for layertype in [\"reg\", \"id\"]:\n",
    "    for layernum in range(model_kwargs[\"num_convs\"]):\n",
    "        att_fn = \"attn_conv_{}_{}_0.npz\".format(layertype, layernum)\n",
    "        att_file = np.load(att_fn)\n",
    "        tsne = sklearn.manifold.TSNE()\n",
    "        embed_2d = tsne.fit_transform(att_file[\"x\"][0])\n",
    "        ax = axs[iattn]\n",
    "        plt.sca(axs[iattn])\n",
    "        for typ in typs:\n",
    "            msk = X[:, 0]==typ\n",
    "            alpha = np.ones(len(msk), dtype=np.float32)\n",
    "            alpha[y[:, 0]==0] = 0.2\n",
    "            plt.scatter(\n",
    "                embed_2d[msk, 0],\n",
    "                embed_2d[msk, 1],\n",
    "                label=ELEM_NAMES_CMS[typ],\n",
    "                alpha=alpha[msk],\n",
    "                s=energy_markers[msk]\n",
    "            )\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        plt.legend(fontsize=12, ncols=2)\n",
    "        plt.title(r\"$z_{{{}}}$\".format(layertype+str(layernum)), fontsize=12)\n",
    "        plt.xlim(-150,150)\n",
    "        plt.ylim(-150,150)\n",
    "        iattn += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4c1348-dc8a-43d0-8942-f5a98b812cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_etaphi = [X[:, 2:5].numpy() for X in X_feat_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5f9426-ae35-4a5c-ab6c-5aed8141feec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def calculate_delta_r(particles):\n",
    "    \"\"\"\n",
    "    Calculates the Delta R matrix for a set of particles.\n",
    "\n",
    "    Args:\n",
    "        particles (np.ndarray): An N x 3 matrix where N is the number of particles.\n",
    "                                Each row contains [eta, sin(phi), cos(phi)].\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: An N x N matrix containing the Delta R values between\n",
    "                    each pair of particles.\n",
    "    \"\"\"\n",
    "    n_particles = particles.shape[0]\n",
    "    delta_r_matrix = np.empty((n_particles, n_particles), dtype=np.float64)\n",
    "\n",
    "    # Calculate phi for all particles first\n",
    "    phis = np.empty(n_particles, dtype=np.float64)\n",
    "    for i in range(n_particles):\n",
    "        phis[i] = np.arctan2(particles[i, 1], particles[i, 2]) # atan2(sin(phi), cos(phi))\n",
    "\n",
    "    for i in range(n_particles):\n",
    "        for j in range(n_particles):\n",
    "            if i == j:\n",
    "                delta_r_matrix[i, j] = 0.0\n",
    "                continue\n",
    "\n",
    "            eta1 = particles[i, 0]\n",
    "            phi1 = phis[i]\n",
    "\n",
    "            eta2 = particles[j, 0]\n",
    "            phi2 = phis[j]\n",
    "\n",
    "            delta_eta = eta1 - eta2\n",
    "            \n",
    "            delta_phi = phi1 - phi2\n",
    "            delta_phi = np.arctan2(np.sin(delta_phi), np.cos(delta_phi))\n",
    "\n",
    "            delta_r_matrix[i, j] = np.sqrt(delta_eta**2 + delta_phi**2)\n",
    "            \n",
    "    return delta_r_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42ee911-7996-4d30-928b-cc01974faf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dr_mat = calculate_delta_r(X_etaphi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9623300d-598e-4133-bc35-a7609575c7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_dr(layertype):\n",
    "    fig, axes = plt.subplots(2, model_kwargs[\"num_convs\"], figsize=(model_kwargs[\"num_convs\"]*6, 2*6), constrained_layout=True, gridspec_kw={'height_ratios': [1, 1]})\n",
    "    for nlayer in range(model_kwargs[\"num_convs\"]):\n",
    "        att_mat = np.load(\"attn_conv_{}_{}_0.npz\".format(layertype, nlayer))[\"att\"]\n",
    "    \n",
    "        # Plotting parameters\n",
    "        imshow_norm = matplotlib.colors.LogNorm(vmin=1e-6, vmax=1)\n",
    "        hist2d_bins = (np.logspace(-2, 2, 100), np.logspace(-10, 0, 100))\n",
    "        cmap_choice = \"hot_r\"\n",
    "        \n",
    "        # Top row: Attention Matrices\n",
    "        ax = axes[0, nlayer]\n",
    "        im = ax.imshow(att_mat[0], cmap=cmap_choice, norm=imshow_norm)\n",
    "        #fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "        ax.set_title(\"self-attention $A^{\" + (layertype + str(nlayer)) + \"}_{ij}$\")\n",
    "        ax.set_xlabel(\"elem. i\")\n",
    "        ax.set_ylabel(\"elem. j\")\n",
    "        ax.set_xticks([], [])\n",
    "        ax.set_yticks([], [])\n",
    "        \n",
    "        \n",
    "        # Bottom row: DR-Attention Correlations\n",
    "        ax = axes[1, nlayer]\n",
    "        \n",
    "        counts, xedges, yedges, im = ax.hist2d(\n",
    "            dr_mat.flatten(),\n",
    "            att_mat.flatten(),\n",
    "            bins=hist2d_bins,\n",
    "            cmap=cmap_choice,\n",
    "            norm=matplotlib.colors.LogNorm(vmin=1, vmax=1e6)\n",
    "        )\n",
    "        #fig.colorbar(im, ax=ax, fraction=0.046)\n",
    "        ax.set_yscale(\"log\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        #ax.set_title(titles_corr[i])\n",
    "        ax.set_xlabel(\"$\\Delta R_{ij}$\")\n",
    "        ax.set_ylabel(\"$A_{ij}$\")\n",
    "        ax.set_box_aspect(1)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a276fe5-29db-49de-b189-e546c7801dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_dr(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93540ceb-2a67-4ac9-ad8c-9b998a8606f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_attention_dr(\"reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5852e242-269f-453c-a933-c31797e4d6d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
