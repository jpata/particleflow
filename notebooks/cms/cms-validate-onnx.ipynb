{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d52b47c-e6c7-4399-9686-e240da62fa0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import pickle as pkl\n",
    "import sys\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import tensorflow_datasets as tfds\n",
    "\n",
    "import awkward\n",
    "import vector\n",
    "import fastjet\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import torch.nn as nn\n",
    "from torch import Tensor\n",
    "\n",
    "import onnxscript\n",
    "import onnx\n",
    "import onnxruntime as rt\n",
    "from onnxconverter_common import float16\n",
    "from onnxscript.function_libs.torch_lib.tensor_typing import TFloat\n",
    "\n",
    "sys.path.append(\"../../mlpf\")\n",
    "from pyg.mlpf import MLPF\n",
    "from pyg.utils import unpack_predictions, unpack_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8413bda-1e12-44fd-968e-590806f3da4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from onnxscript import opset17 as op\n",
    "opset_version = 17\n",
    "custom_opset = onnxscript.values.Opset(domain=\"onnx-script\", version=1)\n",
    "msft_op = onnxscript.values.Opset(\"com.microsoft\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06d0792-ec61-4168-802c-7e914f1d449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tfds datasets are here:\n",
    "data_dir = \"/scratch/persistent/joosep/tensorflow_datasets/\"\n",
    "dataset = \"cms_pf_ttbar\"\n",
    "\n",
    "#model checkpoints are here:\n",
    "outdir = \"../../experiments/pyg-cms_20240430_094836_751206\"\n",
    "\n",
    "#Load model arguments from existing training\n",
    "model_state = torch.load(\n",
    "    outdir + \"/checkpoints/checkpoint-25-17.631161.pth\", map_location=torch.device(\"cpu\")\n",
    ")\n",
    "with open(f\"{outdir}/model_kwargs.pkl\", \"rb\") as f:\n",
    "    model_kwargs = pkl.load(f)\n",
    "\n",
    "#this is needed to configure com.microsoft.MultiHeadAttention\n",
    "NUM_HEADS = model_kwargs[\"num_heads\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac122980-f83f-4d7e-a6c3-6d75843d5078",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model from our codebase\n",
    "model = MLPF(**model_kwargs)\n",
    "model.eval()\n",
    "model.load_state_dict(model_state[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d867be21-685e-45d4-828b-3f9855ca8743",
   "metadata": {},
   "outputs": [],
   "source": [
    "#these are copied from mlpf.py for explicit clarity\n",
    "def get_activation(activation):\n",
    "    if activation == \"elu\":\n",
    "        act = nn.ELU\n",
    "    elif activation == \"relu\":\n",
    "        act = nn.ReLU\n",
    "    elif activation == \"relu6\":\n",
    "        act = nn.ReLU6\n",
    "    elif activation == \"leakyrelu\":\n",
    "        act = nn.LeakyReLU\n",
    "    return act\n",
    "\n",
    "def ffn(input_dim, output_dim, width, act, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(input_dim, width),\n",
    "        act(),\n",
    "        torch.nn.LayerNorm(width),\n",
    "        nn.Dropout(dropout),\n",
    "        nn.Linear(width, output_dim),\n",
    "    )\n",
    "\n",
    "class RegressionOutput(nn.Module):\n",
    "    def __init__(self, mode, embed_dim, width, act, dropout, elemtypes):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.elemtypes = elemtypes\n",
    "        self.nn = ffn(embed_dim, 2, width, act, dropout)\n",
    "\n",
    "    def forward(self, elems, x, orig_value):\n",
    "        nn_out = self.nn(x)\n",
    "        nn_out = orig_value * nn_out[..., 0:1] + nn_out[..., 1:2]\n",
    "        return nn_out\n",
    "\n",
    "class SimpleMultiheadAttention(nn.MultiheadAttention):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        num_heads: int,\n",
    "        dropout: float = 0.0,\n",
    "        device=None,\n",
    "        dtype=None,\n",
    "    ) -> None:\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "        bias = True\n",
    "        batch_first = True\n",
    "        super().__init__(embed_dim, num_heads, dropout, bias=bias, batch_first=batch_first, **factory_kwargs)\n",
    "        self.head_dim = int(embed_dim // num_heads)\n",
    "        \n",
    "        self.out_proj = nn.Linear(self.embed_dim, self.embed_dim, bias=bias, **factory_kwargs)\n",
    "        self.export_onnx = False\n",
    "\n",
    "    def forward(self, q: Tensor, k: Tensor, v: Tensor) -> Tensor:\n",
    "\n",
    "        bs, seq_len, embed_dim = q.size()\n",
    "        head_dim = self.head_dim\n",
    "        num_heads = self.num_heads\n",
    "\n",
    "        wq, wk, wv = torch.split(self.in_proj_weight.data, [self.embed_dim, self.embed_dim, self.embed_dim], dim=0)\n",
    "        bq, bk, bv = torch.split(self.in_proj_bias.data, [self.embed_dim, self.embed_dim, self.embed_dim], dim=0)\n",
    "\n",
    "        q = torch.matmul(q, wq.T) + bq\n",
    "        k = torch.matmul(k, wk.T) + bk\n",
    "        v = torch.matmul(v, wv.T) + bv\n",
    "\n",
    "        if not self.export_onnx:\n",
    "            q = q.reshape(bs, seq_len, num_heads, head_dim).transpose(1,2).reshape(bs*num_heads, seq_len, head_dim)\n",
    "            k = k.reshape(bs, seq_len, num_heads, head_dim).transpose(1,2).reshape(bs*num_heads, seq_len, head_dim)\n",
    "            v = v.reshape(bs, seq_len, num_heads, head_dim).transpose(1,2).reshape(bs*num_heads, seq_len, head_dim)\n",
    "\n",
    "        #this function will have different shape signatures in native torch and in ONNX com.microsoft.MultiHeadAttention\n",
    "        attn_output = torch.nn.functional.scaled_dot_product_attention(q, k, v, dropout_p=self.dropout)\n",
    "        \n",
    "        if not self.export_onnx:\n",
    "            attn_output = attn_output.reshape(bs, num_heads, seq_len, head_dim).transpose(1,2).reshape(bs, seq_len, num_heads*head_dim)\n",
    "        \n",
    "        assert list(attn_output.size()) == [bs, seq_len, num_heads * head_dim]\n",
    "        attn_output = self.out_proj(attn_output)\n",
    "        return attn_output, None\n",
    "\n",
    "class SimpleSelfAttentionLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        activation=\"elu\",\n",
    "        embedding_dim=128,\n",
    "        num_heads=2,\n",
    "        width=128,\n",
    "        dropout_mha=0.1,\n",
    "        dropout_ff=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = get_activation(activation)\n",
    "        self.mha = SimpleMultiheadAttention(embedding_dim, num_heads, dropout=dropout_mha)\n",
    "        self.norm0 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.norm1 = torch.nn.LayerNorm(embedding_dim)\n",
    "        self.seq = torch.nn.Sequential(\n",
    "            nn.Linear(embedding_dim, width), self.act(), nn.Linear(width, embedding_dim), self.act()\n",
    "        )\n",
    "        self.dropout = torch.nn.Dropout(dropout_ff)\n",
    "\n",
    "    def forward(self, x: Tensor, mask: Tensor):\n",
    "        mha_out = self.mha(x, x, x)[0]\n",
    "\n",
    "        x = x + mha_out\n",
    "        x = self.norm0(x)\n",
    "        x = x + self.seq(x)\n",
    "        x = self.norm1(x)\n",
    "        x = self.dropout(x)\n",
    "        x = x * mask.unsqueeze(-1)\n",
    "        return x\n",
    "\n",
    "class SimpleMLPF(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim=34,\n",
    "        num_classes=8,\n",
    "        embedding_dim=128,\n",
    "        width=128,\n",
    "        num_convs=2,\n",
    "        dropout_ff=0.0,\n",
    "        activation=\"elu\",\n",
    "        layernorm=True,\n",
    "        # element types which actually exist in the dataset\n",
    "        elemtypes_nonzero=[1, 4, 5, 6, 8, 9, 10, 11],\n",
    "        # self-attention specific parameters\n",
    "        num_heads=16,\n",
    "        head_dim=16,\n",
    "        dropout_conv_reg_mha=0.0,\n",
    "        dropout_conv_reg_ff=0.0,\n",
    "        dropout_conv_id_mha=0.0,\n",
    "        dropout_conv_id_ff=0.0,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.act = get_activation(activation)\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.num_convs = num_convs\n",
    "\n",
    "        self.elemtypes_nonzero = elemtypes_nonzero\n",
    "\n",
    "        embedding_dim = num_heads * head_dim\n",
    "        width = num_heads * head_dim\n",
    "\n",
    "        # embedding of the inputs\n",
    "        self.nn0_id = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "        self.nn0_reg = ffn(self.input_dim, embedding_dim, width, self.act, dropout_ff)\n",
    "\n",
    "        self.conv_id = nn.ModuleList()\n",
    "        self.conv_reg = nn.ModuleList()\n",
    "\n",
    "        for i in range(num_convs):\n",
    "            self.conv_id.append(\n",
    "                SimpleSelfAttentionLayer(\n",
    "                    activation=activation,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_id_mha,\n",
    "                    dropout_ff=dropout_conv_id_ff,\n",
    "                )\n",
    "            )\n",
    "            self.conv_reg.append(\n",
    "                SimpleSelfAttentionLayer(\n",
    "                    activation=activation,\n",
    "                    embedding_dim=embedding_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    width=width,\n",
    "                    dropout_mha=dropout_conv_reg_mha,\n",
    "                    dropout_ff=dropout_conv_reg_ff,\n",
    "                )\n",
    "            )\n",
    "\n",
    "        decoding_dim = self.input_dim + embedding_dim\n",
    "\n",
    "        # DNN that acts on the node level to predict the PID\n",
    "        self.nn_id = ffn(decoding_dim, num_classes, width, self.act, dropout_ff)\n",
    "\n",
    "        # elementwise DNN for node momentum regression\n",
    "        embed_dim = decoding_dim + num_classes\n",
    "        self.nn_pt = RegressionOutput(\"linear\", embed_dim, width, self.act, dropout_ff, self.elemtypes_nonzero)\n",
    "        self.nn_eta = RegressionOutput(\"linear\", embed_dim, width, self.act, dropout_ff, self.elemtypes_nonzero)\n",
    "        self.nn_sin_phi = RegressionOutput(\"linear\", embed_dim, width, self.act, dropout_ff, self.elemtypes_nonzero)\n",
    "        self.nn_cos_phi = RegressionOutput(\"linear\", embed_dim, width, self.act, dropout_ff, self.elemtypes_nonzero)\n",
    "        self.nn_energy = RegressionOutput(\"linear\", embed_dim, width, self.act, dropout_ff, self.elemtypes_nonzero)\n",
    "\n",
    "    # @torch.compile\n",
    "    def forward(self, X_features, mask):\n",
    "        Xfeat_normed = X_features\n",
    "\n",
    "        embeddings_id, embeddings_reg = [], []\n",
    "        embedding_id = self.nn0_id(Xfeat_normed)\n",
    "        embedding_reg = self.nn0_reg(Xfeat_normed)\n",
    "\n",
    "        for num, conv in enumerate(self.conv_id):\n",
    "            conv_input = embedding_id if num == 0 else embeddings_id[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_id.append(out_padded)\n",
    "        for num, conv in enumerate(self.conv_reg):\n",
    "            conv_input = embedding_reg if num == 0 else embeddings_reg[-1]\n",
    "            out_padded = conv(conv_input, mask)\n",
    "            embeddings_reg.append(out_padded)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        preds_id = self.nn_id(final_embedding_id)\n",
    "\n",
    "        final_embedding_id = torch.cat([Xfeat_normed] + [embeddings_id[-1]], axis=-1)\n",
    "        final_embedding_reg = torch.cat([Xfeat_normed] + [embeddings_reg[-1]] + [preds_id], axis=-1)\n",
    "\n",
    "        # The PFElement feature order in X_features defined in fcc/postprocessing.py\n",
    "        preds_pt = self.nn_pt(X_features, final_embedding_reg, X_features[..., 1:2])\n",
    "        preds_eta = self.nn_eta(X_features, final_embedding_reg, X_features[..., 2:3])\n",
    "        preds_sin_phi = self.nn_sin_phi(X_features, final_embedding_reg, X_features[..., 3:4])\n",
    "        preds_cos_phi = self.nn_cos_phi(X_features, final_embedding_reg, X_features[..., 4:5])\n",
    "        preds_energy = self.nn_energy(X_features, final_embedding_reg, X_features[..., 5:6])\n",
    "        preds_momentum = torch.cat([preds_pt, preds_eta, preds_sin_phi, preds_cos_phi, preds_energy], axis=-1)\n",
    "\n",
    "        return preds_id, preds_momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19c4ac-e579-46c2-86d0-6f664f4b8625",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple = SimpleMLPF(\n",
    "        input_dim=model_kwargs[\"input_dim\"],\n",
    "        num_classes=model_kwargs[\"num_classes\"],\n",
    "        embedding_dim=model_kwargs[\"num_heads\"]*model_kwargs[\"head_dim\"],\n",
    "        width=model_kwargs[\"num_heads\"]*model_kwargs[\"head_dim\"],\n",
    "        num_convs=model_kwargs[\"num_convs\"],\n",
    "        dropout_ff=model_kwargs[\"dropout_ff\"],\n",
    "        activation=model_kwargs[\"activation\"],\n",
    "        layernorm=True,\n",
    "        # element types which actually exist in the dataset\n",
    "        elemtypes_nonzero=model_kwargs[\"elemtypes_nonzero\"],\n",
    "        # self-attention specific parameters\n",
    "        num_heads=model_kwargs[\"num_heads\"],\n",
    "        head_dim=model_kwargs[\"head_dim\"],\n",
    "        dropout_conv_reg_mha=model_kwargs[\"dropout_conv_reg_mha\"],\n",
    "        dropout_conv_reg_ff=model_kwargs[\"dropout_conv_reg_ff\"],\n",
    "        dropout_conv_id_mha=model_kwargs[\"dropout_conv_id_mha\"],\n",
    "        dropout_conv_id_ff=model_kwargs[\"dropout_conv_id_ff\"],\n",
    ")\n",
    "model_simple.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb9248e-a729-4171-88a7-3ab06c1268e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_simple.load_state_dict(model_state[\"model_state_dict\"])\n",
    "\n",
    "dummy_features = torch.randn(1, 256, model_kwargs[\"input_dim\"]).float()\n",
    "dummy_mask = torch.randn(1, 256).bool()\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_simple,\n",
    "    (dummy_features, dummy_mask),\n",
    "    \"test_fp32_unfused.onnx\",\n",
    "    opset_version=opset_version,\n",
    "    verbose=False,\n",
    "    input_names=[\n",
    "        \"Xfeat_normed\", \"mask\",\n",
    "    ],\n",
    "    output_names=[\"id\", \"momentum\"],\n",
    "    dynamic_axes={\n",
    "        \"Xfeat_normed\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"mask\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"id\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"momentum\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecf124-8610-476b-9a08-94a3513d1074",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_simple_fused = copy.deepcopy(model_simple)\n",
    "#configure the model to run in (batch, seq_len, num_heads*head_dim) 3d-mode.\n",
    "for conv in model_simple_fused.conv_id + model_simple_fused.conv_reg:\n",
    "    conv.mha.export_onnx = True\n",
    "\n",
    "#register our custom op that calls out to the fast MultiHeadAttention implementation\n",
    "@onnxscript.script(custom_opset)\n",
    "def SDPA(\n",
    "    query: TFloat,\n",
    "    key: TFloat,\n",
    "    value: TFloat,\n",
    ") -> TFloat:\n",
    "\n",
    "    # Unlike pytorch scaled_dot_product_attention,\n",
    "    # the input here MUST BE (batch, seq_len, num_head*head_dim).\n",
    "    # Also, for the op to be fast on GPU, it needs to run in float16.\n",
    "    query = op.Cast(query, to=onnx.TensorProto.FLOAT16)\n",
    "    key = op.Cast(key, to=onnx.TensorProto.FLOAT16)\n",
    "    value = op.Cast(value, to=onnx.TensorProto.FLOAT16)\n",
    "    output, _, _ = msft_op.MultiHeadAttention(query, key, value, num_heads=NUM_HEADS)\n",
    "    output = op.Cast(output, to=onnx.TensorProto.FLOAT)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# setType API provides shape/type to ONNX shape/type inference\n",
    "def custom_scaled_dot_product_attention(\n",
    "    g, query: TFloat, key: TFloat, value: TFloat, attn_mask=None, dropout_p=0.0, is_causal=False, scale=None\n",
    "):\n",
    "    return g.onnxscript_op(SDPA, query, key, value).setType(query.type())\n",
    "\n",
    "\n",
    "#the warning 'MultiHeadAttention' is not a known op in 'com.microsoft' is not actually important\n",
    "print(\"registering custom op for scaled_dot_product_attention\")\n",
    "torch.onnx.register_custom_op_symbolic(\n",
    "    symbolic_name=\"aten::scaled_dot_product_attention\",\n",
    "    symbolic_fn=custom_scaled_dot_product_attention,\n",
    "    opset_version=opset_version,\n",
    ")\n",
    "\n",
    "torch.onnx.export(\n",
    "    model_simple_fused,\n",
    "    (dummy_features, dummy_mask),\n",
    "    \"test_fp32_fused.onnx\",\n",
    "    opset_version=opset_version,\n",
    "    verbose=False,\n",
    "    input_names=[\n",
    "        \"Xfeat_normed\", \"mask\",\n",
    "    ],\n",
    "    output_names=[\"id\", \"momentum\"],\n",
    "    dynamic_axes={\n",
    "        \"Xfeat_normed\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"mask\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"id\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "        \"momentum\": {0: \"num_batch\", 1: \"num_elements\"},\n",
    "    },\n",
    ")\n",
    "\n",
    "sess_options = rt.SessionOptions()\n",
    "onnx_sess_unfused = rt.InferenceSession(\"test_fp32_unfused.onnx\", sess_options, providers=[\"CPUExecutionProvider\"])\n",
    "onnx_sess_fused = rt.InferenceSession(\"test_fp32_fused.onnx\", sess_options, providers=[\"CPUExecutionProvider\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc3e15-be3f-4dcd-9f31-7f6e1eb82561",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffs_vec(preds):\n",
    "    diffs = [torch.mean(torch.abs(torch.flatten(pred[i]-preds[i]))).item() for i in range(len(preds))]\n",
    "    return diffs\n",
    "\n",
    "def particles_to_jets(pred):\n",
    "    jetdef = fastjet.JetDefinition(fastjet.antikt_algorithm, 0.4)\n",
    "    ypred = unpack_predictions(pred)\n",
    "    for k, v in ypred.items():\n",
    "        ypred[k] = v[mask].detach().cpu().contiguous().numpy()\n",
    "    \n",
    "    counts = torch.sum(mask, axis=1).cpu().numpy()\n",
    "    clsid = awkward.unflatten(ypred[\"cls_id\"], counts)\n",
    "    msk = clsid != 0\n",
    "    p4 = awkward.unflatten(ypred[\"p4\"], counts)\n",
    "    \n",
    "    vec = vector.awk(\n",
    "        awkward.zip(\n",
    "            {\n",
    "                \"pt\": p4[msk][:, :, 0],\n",
    "                \"eta\": p4[msk][:, :, 1],\n",
    "                \"phi\": p4[msk][:, :, 2],\n",
    "                \"e\": p4[msk][:, :, 3],\n",
    "            }\n",
    "        )\n",
    "    )\n",
    "    cluster = fastjet.ClusterSequence(vec.to_xyzt(), jetdef)\n",
    "    jets = cluster.inclusive_jets(min_pt=10)\n",
    "    return awkward.to_numpy(awkward.flatten(jets.pt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff46497-e83d-48ec-99e6-140ed7047111",
   "metadata": {},
   "outputs": [],
   "source": [
    "builder = tfds.builder(dataset, data_dir=data_dir)\n",
    "ds = builder.as_data_source(split=\"test\")\n",
    "max_events = 50\n",
    "events_per_batch = 1\n",
    "inds = range(0, max_events, events_per_batch)\n",
    "\n",
    "jets_mlpf = []\n",
    "jets_mlpf_simple = []\n",
    "jets_onnx_unfused = []\n",
    "jets_onnx_fused = []\n",
    "\n",
    "for ind in inds:\n",
    "    ds_elems = [ds[i] for i in range(ind,ind+events_per_batch)]\n",
    "    X_features = [torch.tensor(elem[\"X\"]).to(torch.float32) for elem in ds_elems]\n",
    "    y_targets = [torch.tensor(elem[\"ygen\"]).to(torch.float32) for elem in ds_elems]\n",
    "\n",
    "    #batch the data into [batch_size, num_elems, num_features]\n",
    "    X_features_padded = pad_sequence(X_features, batch_first=True)\n",
    "    y_targets_padded = pad_sequence(y_targets, batch_first=True)\n",
    "    print(\"batch\", ind, X_features_padded.shape)\n",
    "    mask = X_features_padded[:, :, 0]!=0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        print(\"running base model\")\n",
    "        pred = model(X_features_padded, mask)\n",
    "        print(\"running simplified model\")\n",
    "        pred_simple = model_simple(X_features_padded, mask)\n",
    "\n",
    "    pred = tuple(p.detach() for p in pred)\n",
    "    jets_mlpf.append(particles_to_jets(pred))\n",
    "    \n",
    "    pred_simple = tuple(p.detach() for p in pred_simple)\n",
    "    jets_mlpf_simple.append(particles_to_jets(pred_simple))\n",
    "    \n",
    "    torch.testing.assert_close(pred[0], pred_simple[0], atol=0.01, rtol=0.01)\n",
    "    torch.testing.assert_close(pred[1], pred_simple[1], atol=0.01, rtol=0.01)\n",
    "    \n",
    "    diffs = diffs_vec(pred_simple)\n",
    "    print(\"diffs: {:.4f} {:.4f}\".format(*diffs))\n",
    "\n",
    "    print(\"running ONNX unfused model\")\n",
    "    pred_onnx_unfused = onnx_sess_unfused.run(None, {\"Xfeat_normed\": X_features_padded.numpy(), \"mask\": mask.numpy()})\n",
    "    pred_onnx_unfused = tuple(torch.tensor(p) for p in pred_onnx_unfused)\n",
    "    jets_onnx_unfused.append(particles_to_jets(pred_onnx_unfused))\n",
    "    diffs = diffs_vec(pred_onnx_unfused)\n",
    "    print(\"diffs: {:.4f} {:.4f}\".format(*diffs))\n",
    "    torch.testing.assert_close(pred[0], pred_onnx_unfused[0], atol=0.01, rtol=0.01)\n",
    "    torch.testing.assert_close(pred[1], pred_onnx_unfused[1], atol=0.01, rtol=0.01)\n",
    "    \n",
    "    print(\"running ONNX fused model\")\n",
    "    pred_onnx_fused = onnx_sess_fused.run(None, {\"Xfeat_normed\": X_features_padded.numpy(), \"mask\": mask.numpy()})\n",
    "    pred_onnx_fused = tuple(torch.tensor(p) for p in pred_onnx_fused)\n",
    "    jets_onnx_fused.append(particles_to_jets(pred_onnx_fused))\n",
    "    diffs = diffs_vec(pred_onnx_fused)\n",
    "    print(\"diffs: {:.4f} {:.4f}\".format(*diffs))\n",
    "    torch.testing.assert_close(pred[0], pred_onnx_fused[0], atol=0.01, rtol=0.01)\n",
    "    torch.testing.assert_close(pred[1], pred_onnx_fused[1], atol=0.01, rtol=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c263737a-5def-4f83-ad6a-2243029f3c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boost_histogram as bh\n",
    "import mplhep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1435d5e-efba-44f7-aa29-54481d8490dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_overflow_into_last_bin(all_values):\n",
    "    values = all_values[1:-1]\n",
    "    values[-1] = values[-1] + all_values[-1]\n",
    "    values[0] = values[0] + all_values[0]\n",
    "    return values\n",
    "    \n",
    "def to_bh(data, bins, cumulative=False):\n",
    "    h1 = bh.Histogram(bh.axis.Variable(bins))\n",
    "    h1.fill(data)\n",
    "    if cumulative:\n",
    "        h1[:] = np.sum(h1.values()) - np.cumsum(h1)\n",
    "    h1[:] = sum_overflow_into_last_bin(h1.values(flow=True)[:])\n",
    "    return h1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04fb152-8291-49d2-b6b6-c9d18b8d66b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(10,100,51)\n",
    "h0 = to_bh(np.concatenate(jets_mlpf), bins=b)\n",
    "h1 = to_bh(np.concatenate(jets_onnx_unfused), bins=b)\n",
    "h2 = to_bh(np.concatenate(jets_onnx_fused), bins=b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026531f-07d7-4451-be73-caf68960a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "mplhep.histplot(h0, label=\"pytorch\", lw=1)\n",
    "mplhep.histplot(h1, label=\"onnx unfused\", lw=1)\n",
    "mplhep.histplot(h2, label=\"onnx fused\", lw=1)\n",
    "plt.legend()\n",
    "plt.xlabel(\"Jet pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a5a354a-ea10-4f47-9577-a6495130d5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.linspace(10,100,21)\n",
    "h0 = to_bh(np.concatenate(jets_mlpf), bins=b)\n",
    "h1 = to_bh(np.concatenate(jets_onnx_unfused), bins=b)\n",
    "h2 = to_bh(np.concatenate(jets_onnx_fused), bins=b)\n",
    "\n",
    "plt.plot(h0.axes[0].centers, (h1/h0).values(), marker=\"o\", ms=2.0, lw=1.0)\n",
    "plt.plot(h0.axes[0].centers, (h2/h0).values(), marker=\"o\", ms=2.0, lw=1.0)\n",
    "plt.ylim(0.8,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8835ce80-d1a4-4735-ba36-0515930c2ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
